{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oqmuw3GzEvz",
        "outputId": "01acca55-b337-494f-d4c3-ffc22d6b054e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading PyMuPDF-1.24.5-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyMuPDFb==1.24.3 (from pymupdf)\n",
            "  Downloading PyMuPDFb-1.24.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDFb, pymupdf\n",
            "Successfully installed PyMuPDFb-1.24.3 pymupdf-1.24.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install spacy textstat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwrKaWREzSyL",
        "outputId": "727c4a4e-5b19-454a-eb4f-35b6fc75e457"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Collecting textstat\n",
            "  Downloading textstat-0.7.3-py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.1/105.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.7.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Collecting pyphen (from textstat)\n",
            "  Downloading pyphen-0.15.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.6.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Installing collected packages: pyphen, textstat\n",
            "Successfully installed pyphen-0.15.0 textstat-0.7.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqnI-6esD7s-",
        "outputId": "9072ec25-b05f-4eca-fbcd-ba4f77250d52"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-surprise\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.11.4)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp310-cp310-linux_x86_64.whl size=2357243 sha256=f5ea368920d66f4b81b6facdfba4f10a6f794f646ee2f994832adac69de9c9c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/3f/df/6acbf0a40397d9bf3ff97f582cc22fb9ce66adde75bc71fd54\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "dSI6dkXYwS54"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pymupdf\n",
        "import spacy\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "from textstat import textstat  # To calculate reading ease\n",
        "from sklearn.model_selection import train_test_split\n",
        "from surprise import Dataset, Reader, SVD\n",
        "from surprise.model_selection import cross_validate\n",
        "from surprise.model_selection import GridSearchCV\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the spaCy model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Define the folder containing the PDFs\n",
        "pdf_folder = '/content/'\n",
        "db_name = 'pdfnotes_metadata.db'\n",
        "# Function to extract text from specific pages\n",
        "def extract_text_from_pages(pdf_path, page_numbers):\n",
        "    doc = pymupdf.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page_num in page_numbers:\n",
        "        page = doc.load_page(page_num - 1)  # page numbers are 0-indexed in pymupdf\n",
        "        text += page.get_text()\n",
        "    return text\n",
        "\n",
        "# Function to estimate reading duration\n",
        "def estimate_reading_duration(text, wpm=200):\n",
        "    word_count = len(text.split())\n",
        "    duration_minutes = word_count / wpm\n",
        "    return f\"{int(duration_minutes)} minutes\"\n",
        "\n",
        "# Function to determine difficulty based on Flesch Reading Ease score\n",
        "def determine_difficulty(text):\n",
        "    flesch_score = textstat.flesch_reading_ease(text)\n",
        "    if flesch_score >= 80:\n",
        "        return \"Easy\"\n",
        "    elif flesch_score >= 50:\n",
        "        return \"Intermediate\"\n",
        "    else:\n",
        "        return \"Hard\"\n",
        "\n",
        "# Function to determine learning style\n",
        "def determine_learning_style(pdf_name, text):\n",
        "    if 'audio' in pdf_name.lower() or 'transcript' in text.lower():\n",
        "        return \"Audio\"\n",
        "    else:\n",
        "        return \"Reading/Writing\"\n",
        "\n",
        "# Function to extract metadata including subject and module\n",
        "def extract_metadata(pdf_name, text):\n",
        "    # Use the filename as the title (without .pdf extension)\n",
        "    title = os.path.splitext(pdf_name)[0]\n",
        "\n",
        "    # Extract subject and module from filename\n",
        "    subject_name, module_name = os.path.splitext(pdf_name)[0].split('-')[:2]\n",
        "    # Assuming subject_name-module_name.pdf format\n",
        "\n",
        "    # Extract keywords (nouns and proper nouns)\n",
        "    nlp_doc = nlp(text)\n",
        "    keywords = [token.lemma_ for token in nlp_doc if token.pos_ in ['NOUN', 'PROPN']]\n",
        "\n",
        "    # Determine difficulty\n",
        "    difficulty = determine_difficulty(text)\n",
        "\n",
        "    # Estimate duration\n",
        "    duration = estimate_reading_duration(text)\n",
        "\n",
        "    # Determine learning style\n",
        "    learning_style = determine_learning_style(pdf_name, text)\n",
        "\n",
        "    # Generate metadata\n",
        "    metadata = {\n",
        "        \"title\": title,\n",
        "        \"keywords\": keywords,\n",
        "        \"difficulty\": difficulty,\n",
        "        \"format\": \"PDF\",\n",
        "        \"duration\": duration,\n",
        "        \"learning_style\": learning_style,\n",
        "        \"subject\": subject_name.strip(),  # Include subject in metadata\n",
        "        \"module\": module_name.strip()  # Include module in metadata\n",
        "    }\n",
        "    return metadata\n",
        "\n",
        "# Function to process all PDFs in the folder\n",
        "def process_pdfs(pdf_folder):\n",
        "    pdf_metadata = []\n",
        "    for pdf_file in os.listdir(pdf_folder):\n",
        "        if pdf_file.endswith('.pdf'):\n",
        "            pdf_path = os.path.join(pdf_folder, pdf_file)\n",
        "\n",
        "            # Extract text from specific pages (e.g., first 5 pages)\n",
        "            text = extract_text_from_pages(pdf_path, range(1, 11))\n",
        "\n",
        "            # Extract metadata including subject and module\n",
        "            metadata = extract_metadata(pdf_file, text)\n",
        "            metadata['file_path'] = pdf_path\n",
        "            pdf_metadata.append(metadata)\n",
        "    return pdf_metadata\n",
        "\n",
        "# Create the database table with subject and module included\n",
        "def create_database(db_name):\n",
        "    conn = sqlite3.connect(db_name)\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute('''\n",
        "        CREATE TABLE IF NOT EXISTS pdfs (\n",
        "            id INTEGER PRIMARY KEY,\n",
        "            title TEXT,\n",
        "            keywords TEXT,\n",
        "            difficulty TEXT,\n",
        "            format TEXT,\n",
        "            duration TEXT,\n",
        "            learning_style TEXT,\n",
        "            subject TEXT,\n",
        "            module TEXT,\n",
        "            file_path TEXT\n",
        "        )\n",
        "    ''')\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "# Insert the metadata into the database with subject and module included\n",
        "def insert_metadata(db_name, metadata_list):\n",
        "    conn = sqlite3.connect(db_name)\n",
        "    cursor = conn.cursor()\n",
        "    for metadata in metadata_list:\n",
        "        # Use a try-except block to handle potential errors during insertion\n",
        "        try:\n",
        "            cursor.execute('''\n",
        "                INSERT INTO pdfs (title, keywords, difficulty, format, duration, learning_style, subject, module, file_path)\n",
        "                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
        "            ''', (metadata['title'], ','.join(metadata['keywords']), metadata['difficulty'], metadata['format'], metadata['duration'], metadata['learning_style'], metadata['subject'], metadata['module'], metadata['file_path']))\n",
        "        except sqlite3.IntegrityError as e:\n",
        "            print(f\"Error inserting {metadata['title']}: {e}\")\n",
        "\n",
        "    # Commit changes and close connection\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "# Function to query and display contents of the pdfs table\n",
        "def query_and_display_pdfs(db_name):\n",
        "    conn = sqlite3.connect(db_name)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # Execute the query\n",
        "    cursor.execute('SELECT * FROM pdfs')\n",
        "    rows = cursor.fetchall()\n",
        "\n",
        "    # Print header\n",
        "    print(f\"{'ID':<5} | {'Title':<30} | {'Keywords':<30} | {'Difficulty':<15} | {'Format':<10} | {'Duration':<10} | {'Learning Style':<20} | {'Subject':<20} | {'Module':<20} | {'File Path':<50}\")\n",
        "    print(\"-\" * 200)\n",
        "\n",
        "    # Print each row\n",
        "    for row in rows:\n",
        "        pdf_id, title, keywords, difficulty, format, duration, learning_style, subject, module, file_path = row\n",
        "        # Truncate long strings for display\n",
        "        title = title[:30] + (title[30:] and '...')\n",
        "        keywords = keywords[:30] + (keywords[30:] and '...')\n",
        "        file_path = file_path[:50] + (file_path[50:] and '...')\n",
        "        print(f\"{pdf_id:<5} | {title:<30} | {keywords:<30} | {difficulty:<15} | {format:<10} | {duration:<10} | {learning_style:<20} | {subject:<20} | {module:<20} | {file_path:<50}\")\n",
        "\n",
        "    # Close connection\n",
        "    conn.close()\n"
      ],
      "metadata": {
        "id": "San_JgoyykEV"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process the PDFs and store metadata in the database\n",
        "metadata_list = process_pdfs(pdf_folder)\n",
        "\n",
        "# Print metadata to verify\n",
        "for metadata in metadata_list:\n",
        "    print(metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dzrLO2ay9a5",
        "outputId": "9f86fc68-1ec5-4c31-8a40-443c669b8096"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'title': 'ML-M2', 'keywords': ['dataset', 'R.', 'Kelley', 'Pace', 'Ronald', 'Barry', 'Sparse', 'Spatial', 'Autoregressions', 'statistic', 'Probability', 'Letters', 'no', '.', 'Real', 'Data', 'Machine', 'Learning', 'world', 'datum', 'dataset', 'thousand', 'dataset', 'sort', 'domain', 'place', 'datum', 'datum', 'repository', 'UC', 'Irvine', 'Machine', 'Learning', 'Repository', 'Kaggle', 'dataset', 'Amazon', 'AWS', 'dataset', '•', 'Meta', 'portal', 'datum', 'repository', 'http://dataportals.org/', 'http://opendatamonitor.eu/', 'http://quandl.com/', 'page', 'datum', 'repository', 'Wikipedia', 'list', 'Machine', 'Learning', 'dataset', 'Quora.com', 'question', 'dataset', 'subreddit', 'chapter', 'California', 'Housing', 'Prices', 'StatLib', 'itory2', 'Figure', 'dataset', 'datum', 'California', 'cen‐', 'sus', 'house', 'Bay', 'Area', 'time', 'quality', 'learning', 'datum', 'attribute', 'feature', 'purpose', '|', 'chapter', 'end', 'end', 'Machine', 'Learning', 'Project', 'MODULE-2', 'Figure', 'California', 'housing', 'price', 'Big', 'Picture', 'welcome', 'Machine', 'Learning', 'Housing', 'Corporation', 'task', 'model', 'housing', 'price', 'California', 'California', 'cen‐', 'sus', 'datum', 'datum', 'metric', 'population', 'income', 'hous‐', 'price', 'block', 'group', 'California', 'Block', 'group', 'unit', 'US', 'Census', 'Bureau', 'sample', 'datum', 'block', 'group', 'population', 'people', 'trict', 'model', 'datum', 'housing', 'price', 'district', 'metric', 'datum', 'scientist', 'thing', 'Machine', 'Learning', 'project', 'checklist', 'one', 'Machine', 'Learning', 'project', 'need', 'chapter', 'item', 'self', 'chapter', 'Frame', 'Problem', 'question', 'boss', 'business', 'objective', 'model', 'end', 'goal', 'company', 'Big', 'Picture', '|', 'piece', 'information', 'Machine', 'Learning', 'system', 'signal', 'reference', 'Shannon', 'information', 'theory', 'signal', 'noise', 'ratio', 'model', 'problem', 'performance', 'measure', 'model', 'effort', 'boss', 'model', 'output', 'prediction', 'district', 'hous‐', 'price', 'Machine', 'Learning', 'system', 'Figure', 'system', 'area', 'nue', 'figure', 'Machine', 'Learning', 'pipeline', 'estate', 'investment', 'Pipelines', 'sequence', 'datum', 'processing', 'component', 'data', 'pipeline', 'pipeline', 'Machine', 'Learning', 'system', 'lot', 'datum', 'datum', 'transformation', 'component', 'component', 'amount', 'datum', 'result', 'data', 'store', 'time', 'component', 'pipeline', 'datum', 'output', 'component', 'self', 'interface', 'component', 'data', 'store', 'system', 'help', 'data', 'flow', 'graph', 'team', 'component', 'component', 'component', 'while', 'output', 'nent', 'architecture', '|', 'chapter', 'end', 'end', 'Machine', 'Learning', 'Project', 'hand', 'component', 'time', 'monitoring', 'datum', 'system', 'perfor‐', 'mance', 'question', 'solution', 'reference', 'performance', 'insight', 'problem', 'boss', 'district', 'housing', 'price', 'expert', 'team', 'date', 'information', 'district', 'housing', 'price', 'rule', 'time', 'estimate', 'case', 'housing', 'price', 'estimate', '%', 'company', 'model', 'district', 'housing', 'price', 'datum', 'district', 'census', 'datum', 'dataset', 'pur‐', 'housing', 'price', 'thousand', 'district', 'datum', 'information', 'system', 'problem', 'Reinforce‐', 'Learning', 'classification', 'task', 'regression', 'task', 'batch', 'learning', 'technique', 'pause', 'question', 'answer', 'task', 'training', 'example', 'instance', 'output', 'district', 'housing', 'price', 'regres‐', 'sion', 'task', 'value', 'regression', 'problem', 'system', 'feature', 'prediction', 'district', 'population', 'income', 'regression', 'problem', 'value', 'district', 'value', 'district', 'multivariate', 'regression', 'problem', 'flow', 'datum', 'system', 'need', 'datum', 'datum', 'memory', 'batch', 'learning', 'datum', 'batch', 'learning', 'work', 'server', 'MapReduce', 'technique', 'learning', 'technique', 'Big', 'Picture', '|', 'Select', 'Performance', 'measure', 'step', 'performance', 'measure', 'performance', 'measure', 'regression', 'problem', 'Root', 'Mean', 'Square', 'Error', 'RMSE', 'idea', 'error', 'system', 'prediction', 'weight', 'error', 'equation', 'formula', 'RMSE', 'equation', 'Root', 'Mean', 'Square', 'Error', 'RMSE', 'RMSE', 'X', 'h', '=', 'm', 'h', 'i', '|', 'chapter', 'end', 'end', 'Machine', 'Learning', 'Project', 'Recall', 'operator', 'column', 'vector', 'row', 'vector', 'vice', 'notation', 'equation', 'Machine', 'Learning', 'notation', 'book', 'm', 'number', 'instance', 'dataset', 'rmse', 'example', 'rmse', 'validation', 'set', 'dis‐', 'trict', 'm', '=', 'x(i', 'vector', 'feature', 'value', 'label', 'ith', 'instance', 'dataset', 'y(i', 'label', 'output', 'value', 'instance', 'example', 'district', 'dataset', 'longitude', 'latitude', 'inhabitant', 'income', 'house', 'value', 'feature', '=', '−118', 'y', '•', 'x', 'matrix', 'feature', 'value', 'label', 'instance', 'dataset', 'row', 'instance', 'ith', 'row', 'transpose', 'x(i', 'x(i))T.4', 'example', 'district', 'matrix', 'x', 'X', '=', 'T', 'T', '⋮', 'T', 'T', '−118', '⋮', '⋮', '⋮', '⋮', 'Big', 'Picture', '|', 'h', 'system', 'prediction', 'function', 'hypothesis', 'system', 'instance', 'feature', 'vector', 'x(i', 'value', 'ŷ(i', 'h(x(i', 'instance', 'ŷ', 'y', 'hat', 'example', 'system', 'housing', 'price', 'district', 'ŷ(1', 'prediction', 'error', 'district', 'ŷ(1', 'y(1', 'RMSE(X', 'h', 'cost', 'function', 'set', 'example', 'hypothesis', 'h.', 'lowercase', 'font', 'value', 'm', 'y(i', 'name', 'h', 'lowercase', 'font', 'vector', 'x(i', 'font', 'matrix', 'X', 'RMSE', 'performance', 'measure', 'regression', 'task', 'context', 'function', 'example', 'district', 'case', 'Mean', 'Absolute', 'Error', 'Average', 'Absolute', 'Deviation', 'equation', 'equation', 'Mean', 'Absolute', 'Error', 'MAE', 'X', 'h', 'm', 'h', 'RMSE', 'MAE', 'way', 'distance', 'vector', 'vector', 'prediction', 'vector', 'target', 'value', 'distance', 'measure', 'norm', 'root', 'sum', 'square', 'RMSE', 'Euclidean', 'norm', 'notion', 'distance', 'ℓ2', 'norm', '∥2', 'sum', 'absolute', 'MAE', 'norm', 'Manhattan', 'norm', 'distance', 'point', 'city', 'city', 'block', 'ℓk', 'norm', 'vector', 'element', '�', 'v0', 'k', '+', 'v1', 'k', '⋯+', 'k', 'k.', 'ℓ0', 'number', 'ele‐', 'ment', 'vector', 'ℓ∞', 'value', 'vector', 'norm', 'index', 'value', 'one', 'RMSE', 'outlier', 'MAE', '|', 'chapter', 'end', 'end', 'Machine', 'Learning', 'Project', 'version', 'Python', 'Python', 'library', 'support', 'Python', 'outlier', 'bell', 'curve', 'RMSE', 'assumption', 'practice', 'assumption', 'other', 'issue', 'example', 'district', 'price', 'system', 'output', 'Machine', 'Learning', 'system', 'price', 'system', 'price', 'category', 'category', 'price', 'them‐', 'self', 'case', 'price', 'sys‐', 'tem', 'category', 'right', 'problem', 'classification', 'task', 'regression', 'task', 'regression', 'system', 'month', 'team', 'charge', 'system', 'price', 'category', 'set', 'light', 'Data', 'time', 'hand', 'laptop', 'code', 'example', 'Jupyter', 'notebook', 'Jupyter', 'note‐', 'book', 'https://github.com/ageron/handson-ml2', 'Workspace', 'Python', 'system', 'workspace', 'directory', 'Machine', 'Learning', 'code', 'dataset', 'terminal', 'command', '$', 'prompt', 'export', 'ML_PATH=\"$HOME', 'ml', '#', 'path', 'mkdir', 'ML_PATH', 'number', 'Python', 'module', 'Jupyter', 'NumPy', 'Pandas', 'Matplotlib', 'Scikit', 'Learn', 'Jupyter', 'module', 'Data', 'page', 'way', 'dependency', 'sys‐', 'Data', '|', 'installation', 'step', 'pip', 'bash', 'shell', 'Linux', 'MacOS', 'system', 'command', 'system', 'Windows', 'Anaconda', 'pip', 'user', 'machine', 'user', 'option', 'administrator', 'right', 'com‐', 'mand', 'Linux', 'MacOSX', 'tool', 'venv', 'virtualenv', 'library', 'virtualenv‐', 'wrapper', 'functionality', 'top', 'virtualenv', 'pyenv', 'switching', 'Python', 'version', 'pipenv', 'packaging', 'tool', 'author', 'request', 'library', 'top', 'pip', 'virtualenv', 'tem', 'packaging', 'system', 'get', 'Ubuntu', 'MacPorts', 'HomeBrew', 'MacOS', 'Python', 'distribution', 'Anaconda', 'packag‐', 'system', 'Python', 'packaging', 'system', 'pip', 'default', 'Python', 'installer', 'Python', '2.7.9).6', 'pip', 'command', 'python3', 'pip', '--version', 'pip', '19.0.2', '/lib', 'python3.6', 'site', 'package', 'python', 'version', 'pip', 'module', 'python3', 'pip', '-U', 'pip', 'pip-19.0.2', 'environment', 'environment', 'project', 'library', 'ver‐', 'sion', 'pip', 'command', 'virtualenv', 'user', 'machine', 'command', 'administrator', 'right', 'python3', 'pip', '-U', 'virtualenv', 'virtualenv', 'virtualenv', 'Python', 'environment', 'cd', 'ML_PATH', 'virtualenv', 'env', 'base', 'prefix', 'New', 'python', 'env', 'bin', 'python3.6', 'env', 'bin', 'python', 'setuptool', 'wheel', '|', 'chapter', 'end', 'end', 'Machine', 'Learning', 'Project', 'note', 'Jupyter', 'version', 'Python', 'language', 'r', 'Octave', 'time', 'environment', 'terminal', 'type', 'cd', 'ML_PATH', 'source', 'env', 'bin', '#', 'Linux', 'MacOSX', '.\\\\env\\\\scripts\\\\activate', '#', 'window', 'environment', 'type', 'deactivate', 'environment', 'package', 'pip', 'environment', 'Python', 'access', 'package', 'access', 'sys‐', 'tem', 'package', 'environment', 'virtualenv', '--system', 'site-', 'package', 'option', 'virtualenv', 'documentation', 'information', 'module', 'dependency', 'sim‐', 'ple', 'pip', 'command', 'virtualenv', 'option', 'administrator', 'right', 'python3', 'pip', '-U', 'jupyter', 'matplotlib', 'numpy', 'pandas', 'scikit', 'learn', 'jupyter', 'jupyter-1.0.0-py2.py3-none-any.whl', 'matplotlib', 'installation', 'module', 'python3', 'import', 'jupyter', 'matplotlib', 'numpy', 'panda', 'output', 'error', 'Jupyter', 'jupyter', 'notebook', 'i', 'NotebookApp', 'notebook', 'directory', 'i', 'NotebookApp', 'kernel', 'i', 'NotebookApp', 'Jupyter', 'Notebook', 'i', 'NotebookApp', 'Use', 'Control', 'C', 'server', 'kernel', 'confirmation', 'Jupyter', 'server', 'terminal', 'port', 'server', 'web', 'browser', 'http://localhost:8888/', 'hap‐', 'server', 'workspace', 'directory', 'env', 'directory', 'virtualenv', 'instruction', 'Python', 'notebook', 'button', 'Python', 'version9', 'Figure', 'thing', 'notebook', 'file', 'Untitled.ipynb', 'workspace', 'Jupyter', 'Python', 'kernel', 'notebook', 'Data', '|'], 'difficulty': 'Intermediate', 'format': 'PDF', 'duration': '15 minutes', 'learning_style': 'Reading/Writing', 'subject': 'ML', 'module': 'M2', 'file_path': '/content/ML-M2.pdf'}\n",
            "{'title': 'ML-M5', 'keywords': ['chapter', 'BAYESIAN', 'LEARNING', 'reasoning', 'approach', 'inference', 'assumption', 'quantity', 'interest', 'probability', 'bution', 'decision', 'proba-', 'bilitie', 'datum', 'machine', 'learning', 'approach', 'evidence', 'tive', 'hypothesis', 'reasoning', 'basis', 'algorithm', 'probability', 'framework', 'operation', 'algorithm', 'probability', 'introduction', 'Bayesian', 'learning', 'method', 'study', 'machine', 'reason', 'Bayesian', 'algorithm', 'probability', 'hypothesis', 'Bayes', 'classifier', 'approach', 'type', 'problem', 'example', 'Michie', 'et', 'al', 'study', 'Bayes', 'classifier', 'learning', 'algorithm', 'decision', 'tree', 'network', 'researcher', 'Bayes', 'classifier', 'algorithm', 'case', 'case', 'method', 'chapter', 'Bayes', 'classifier', 'example', 'use', 'application', 'problem', 'text', 'document', 'news', 'article', 'MODULE-5', 'chafer', 'BAYESIAN', 'LEARNING', 'learning', 'task', 'Bayes', 'classifier', 'algorithm', 'reason', 'method', 'study', 'ma-', 'chine', 'learning', 'perspective', 'algorithm', 'probability', 'exam-', 'ple', 'chapter', 'algorithm', 'FIND', 'S', 'elimination', 'algorithm', 'chapter', 'condition', 'hypothesis', 'training', 'datum', 'analysis', 'design', 'choice', 'network', 'gorithm', 'sum', 'error', 'space', 'network', 'error', 'function', 'cross', 'entropy', 'sum', 'error', 'learn-', 'target', 'function', 'probability', 'perspective', 'bias', 'decision', 'tree', 'algorithm', 'decision', 'tree', 'Minimum', 'Description', 'Length', 'ciple', 'familiarity', 'method', 'u', 'operation', 'algorithm', 'machine', 'learning', 'feature', 'learning', 'method', 'training', 'example', 'probability', 'hypothesis', 'approach', 'algorithm', 'hypothesis', 'example', 'knowledge', 'datum', 'probability', 'hypothesis', 'Bayesian', 'learning', 'knowledge', 'pro-', 'probability', 'candidate', 'hypothesis', 'probability', 'distribution', 'datum', 'hypothesis', 'method', 'hypothesis', 'diction', 'hypothesis', 'pneumonia', 'patient', '%', 'chance', 'recovery', 'instance', 'prediction', 'hypothesis', 'probability', 'case', 'method', 'standard', 'decision', 'making', 'method', 'difficulty', 'method', 'knowledge', 'probability', 'probability', 'advance', 'background', 'knowledge', 'datum', 'assumption', 'form', 'distribu-', 'tion', 'difficulty', 'cost', 'Bayes', 'hypothesis', 'case', 'linear', 'number', 'candidate', 'hypothesis', 'situation', 'cost', 'remainder', 'chapter', 'section', 'intro-', 'Bayes', 'likelihood', 'posteriori', 'probability', 'hypothesis', 'section', 'framework', 'issue', 'algorithm', 'chapter', 'example', 'algorithm', 'likelihood', 'hypothesis', 'assumption', 'section', 'number', 'algorithm', 'probability', 'Bayes', 'classifier', 'Gibbs', 'algorithm', 'Bayes', 'classifier', 'belief', 'network', 'approach', 'reasoning', 'EM', 'algorithm', 'algorithm', 'presence', 'variable', 'bayes', 'theorem', 'machine', 'hypothesis', 'space', 'h', 'training', 'datum', 'D.', 'way', 'hypothesis', 'hypothesis', 'datum', 'D', 'knowledge', 'itie', 'hypothesis', 'H.', 'Bayes', 'theorem', 'method', 'probability', 'Bayes', 'way', 'probability', 'hypothesis', 'probability', 'proba-', 'bilitie', 'datum', 'hypothesis', 'datum', 'Bayes', 'notation', 'probability', 'hypothesis', 'h', 'training', 'datum', 'priorprobability', 'h', 'background', 'knowledge', 'chance', 'h', 'hypothesis', 'knowledge', 'probability', 'candidate', 'hypothesis', 'P(D', 'probability', 'training', 'datum', 'd', 'probability', 'd', 'knowledge', 'hypothesis', 'P(D1h', 'probability', 'datum', 'D', 'world', 'hypothesis', 'h', 'P(xly', 'probability', 'y.', 'machine', 'learning', 'problem', 'probability', 'p', 'h', 'd', 'h', 'training', 'datum', 'D.', 'P', 'h', '1', 'D', 'posteriorprobability', 'h', 'confidence', 'h', 'training', 'datum', 'd', 'probability', 'influence', 'training', 'datum', 'D', 'contrast', 'probability', 'P(h', 'D.', 'Bayes', 'theorem', 'cornerstone', 'method', 'way', 'probability', 'p(hld', 'probability', 'P(h', 'P(D', 'P(D(h', 'Bayes', 'chapter', 'BAYESIAN', 'LEARNING', 'P(h', 'ID', 'P(h', 'P(D1h', 'Bayes', 'p(hl', 'D', 'P(D', 'D', 'indepen-', 'dent', 'h', 'evidence', 'D', 'support', 'h.', 'scenario', 'learner', 'set', 'candidate', 'H', 'hypothesis', 'h', 'e', 'H', 'datum', 'd', 'hypothesis', 'maximum', 'posteriori', 'MAP', 'hypothesis', 'MAP', 'hypothesis', 'Bayes', 'probability', 'candidate', 'hypothesis', 'MAP', 'MAP', 'hypothesis', 'h', '~', 'p', 'argmax', 'P(hlD', '€', 'H', '=', 'argmax', 'h', 'P', 'h', '€', 'H', 'Notice', 'step', 'term', 'P(D', 'independent', 'h.', 'case', 'hypothesis', 'H', 'p(hi', '=', 'h', 'H', 'case', 'Equation', 'term', 'P(D1h', 'hypothesis', 'P(Dlh', 'likelihood', 'datum', 'D', 'h', 'hypothesis', 'P(Dlh', 'likelihood', 'ML', 'hypothesis', 'hML', 'hML', '=', 'argmax', 'P(Dlh', '€', 'H', 'order', 'connection', 'machine', 'learning', 'problem', 'Bayes', 'datum', 'd', 'example', 'target', 'function', 'H', 'space', 'candidate', 'target', 'function', 'fact', 'Bayes', 'theorem', 'discussion', 'h', 'proposition', 'probability', 'sky', 'sky', 'chapter', 'time', 'case', 'H', 'hypothesis', 'space', 'target', 'function', 'datum', 'D', 'example', 'time', 'case', 'H', 'set', 'proposition', 'D', 'kind', 'datum', '6.2.1', 'example', 'Bayes', 'rule', 'diagnosis', 'problem', 'hypothesis', 'patien', 'form', 'cancer', 'patient', 'datum', 'laboratory', 'test', 'outcome', 'knowledge', 'population', 'people', 'disease', 'lab', 'test', 'indicator', 'disease', 'test', 'result', '%', 'case', 'disease', 'result', '%', 'case', 'disease', 'case', 'test', 'result', 'situation', 'probability', 'patient', 'lab', 'test', 'result', 'patient', 'cancer', 'maximum', 'posteriori', 'hypothesis', 'Equation', 'h', 'p', '=', '-cancer', 'hobabilitie', 'quantity', 'P(cancer($', 'step', 'Bayes', 'probability', 'quantity', 'probability', 'datum', 'P(@', 'p($', 'part', 'problem', 'statement', 'fashion', 'P(-cancerl$', 'patient', 'cancer', 'probability', 'cancer', 'probability', 'hypothesis', 'patient', 'cancer', 'example', 'result', 'inference', 'probability', 'order', 'method', 'example', 'hypothesis', 'datum', 'Basic', 'formula', 'probability', 'Table', 'bayes', 'theorem', 'concept', 'LEARNING', 'relationship', 'Bayes', 'theorem', 'problem', 'concept', 'ing', 'Bayes', 'way', 'probability', 'hypothesis', 'training', 'datum', 'basis', 'learning', 'algorithm', 'probability', 'hypothesis', 'section', 'force', 'concept', 'algorithm', 'algorithm', 'chapter', 'result', 'comparison', 'condition', 'algorithm', 'chapter', 'hypothesis', 'force', 'Bayesian', 'CHAPTER', 'BAYESIAN', 'LEARNING', 'product', 'rule', 'probability', 'p', 'A', 'b', 'conjunction', 'event', 'A', 'b', 'Sum', 'rule', 'probability', 'disjunction', 'event', 'A', 'b', 'Bayes', 'probability', 'p(hl', 'D', 'h', 'D', 'Theorem', 'totalprobability', 'event', 'A1', 'A', 'xy', '=', 'l', 'TABLE', 'Summary', 'probability', 'formula', 't', 'algorithm', 'fact', 'probability', '6.3.1', 'Brute', 'Force', 'Bayes', 'Concept', 'Learning', 'concept', 'problem', 'chapter', 'learner', 'hypothesis', 'space', 'H', 'instance', 'space', 'X', 'task', 'target', 'concept', 'c', 'X', 'learner', 'sequence', 'training', 'example', '~', 'l', 'xm', 'dm', 'xi', 'instance', 'X', 'di', 'target', 'value', 'xi', 'di', '=', 'c(xi', 'discussion', 'section', 'sequence', 'instance', 'xm', 'training', 'datum', 'D', 'sequence', 'target', 'value', 'D', '=', 'dl', 'Exercise', 'simplification', 'conclusion', 'section', 'concept', 'algorithm', 'maximum', 'posteriori', 'hypothesis', 'Bayes', 'BRUTE', 'FORCE', 'MAP', 'LEARNING', 'algorithm', 'hypothesis', 'h', 'H', 'probability', 'hypothesis', 'hMAP', 'probability', 'MACHINE', 'LEARNING', 'algorithm', 'computation', 'Bayes', 'hypothesis', 'H', 'D', 'hypothesis', 'space', 'algorithm', 'interest', 'standard', 'performance', 'concept', 'algorithm', 'order', 'iearning', 'problem', 'BRUTE', 'FORCE', 'MAP', 'LEARNING', 'algorithm', 'value', 'P(D1h', 'P(D', 'probability', 'distribution', 'P(D1h', 'way', 'knowledge', 'task', 'assumption', 'training', 'datum', 'd', 'noise', 'di', '=', 'c(xi', 'target', 'concept', 'c', 'hypothesis', 'space', 'h', 'reason', 'hypothesis', 'assumption', 'value', 'P(h', 'knowledge', 'hypothesis', 'probability', 'hypothesis', 'h', 'H.', 'Furthermore', 'target', 'concept', 'H', 'probability', 'constraint', '=', 'h', 'H', 'H', 'choice', 'P(Dlh', 'P(D1h', 'probability', 'ob-', 'target', 'value', 'd', '=', 'dl', 'set', 'instance', 'x', 'x', 'world', 'hypothesis', 'h', 'world', 'h', 'description', 'target', 'concept', 'c', 'noise', 'training', 'datum', 'probability', 'classification', 'di', 'h', '=', 'h(xi', 'di', '#', 'h(xi', '=', 'h(xi', 'D', 'P(D1h', 'word', 'probability', 'datum', 'D', 'hypothesis', 'h', 'D', 'h', 'choice', 'P(Dlh', 'problem', 'BRUTE', 'FORCE', 'MAP', 'LEARNING', 'algorithm', 'step', 'algorithm', 'Bayes', 'probability', 'P(h1D', 'hypothesis', 'h', 'training', 'datum', 'D.', 'CHAPTER', 'BAYESIAN', 'LEARNING', 'Bayes', 'theorem', 'case', 'h', 'training', 'datum', 'D.', 'Equation', 'P(D)h', 'h', 'd', 'p', 'D', '=', 'o', 'h', 'D', 'P(D', 'probability', 'hypothesis', 'inconsistent', 'D', 'case', 'h', 'D.', 'Equation', 'P(Dlh', 'h', 'D', 'h', 'D', 'IVSH', 'DI', 'V', 's', 'h', 'subset', 'hypothesis', 'H', 'D', 'V', 'S', 'h', 'version', 'space', 'h', 'respect', 'D', 'chapter', 'p(d', 'sum', 'hypothesis', 'P(h', 'ID', 'number', 'hypothesis', 'H', 'D', 'definition', 'IVSH', 'DI', 'P(D', 'theorem', 'probability', 'table', 'fact', 'hypothesis', 'vi', '#', 'j)(p(hi', 'hj', 'Bayes', 'theorem', 'probability', 'ID', 'P(h', 'P(D1h', 'h', 'D', 'p(hld', 'IVSH', 'DI', 'number', 'hypothesis', 'H', 'D.', 'lution', 'probability', 'hypothesis', 'Figure', 'figure', 'hypothesis', 'probability', 'training', 'datum', 'accumulate', 'figure', 'b', 'lc', 'probability', 'hypothesis', 'probability', 'hypothesis', 'analysis', 'choice', 'P(Dlh', 'hypothesis', 'probability', 'V', 'SH', 'i', 'hypothesis', 'probability', 'hypothesis', 'MAP', 'hypothesis', '6.3.2', 'MAP', 'Hypotheses', 'Consistent', 'Learners', 'analysis', 'setting', 'hypothesis', 'D', 'MAP', 'hypothesis', 'statement', 'statement', 'class', 'learner', 'learner', 'algorithm', 'learner', 'hypothesis', 'error', 'training', 'example', 'analysis', 'learner', 'MAP', 'hypothesis', 'probability', 'distribution', 'H', 'P(hi', '=', 'P(hj', 'i', 'j', 'ifwe', 'noise', 'training', 'datum', 'P(D', 'Ih', 'd', 'h', 'example', 'concept', 'algorithm', 'FIND', 'S', 'chapter', 'FIND', 'S', 'hypothesis', 'space', 'h', 'pothese', 'hypothesis', 'member', 'version', 'space', 'FIND', 'S', 'pothesis', 'MAP', 'hypothesis', 'probability', 'distribution', 'P(h', 'P(D1h', 'FIND', 'S', 'probability', 'member', 'hypothesis', 'hypothesis', 'c', 'FIGURE', 'Evolution', 'probability', 'p(hld', 'training', 'datum', 'Uniform', 'prior', 'probability', 'hypothesis', 'training', 'data', 'Dl', 'b', 'Dl', 'c', 'probability', 'hypothesis', 'probability', 'increase', 'hypothesis', 'version', 'space', 'chapter', 'BAYESIAN', 'LEARNING', 'version', 'space', 'distribution', 'P(h', 'P(D(h', 'output', 'hypothesis', 'MAP', 'hypothesis', 'way', 'behavior', 'FIND', 'S.', 'probability', 'distribution', 'P(h', 'P(D1h', 'FIND', 'S', 'output', 'MAP', 'hypothesis', 'FIND', 'S', 'spe-', 'cz$c', 'hypothesis', 'version', 'space', 'output', 'hypothesis', 'MAP', 'hypothesis', 'probability', 'distribution', 'hypothesis', 'probability', 'distribution', 'P(h', 'h', 'P(h1', 'p(hz', 'h2', 'FIND', 'S', 'MAP', 'hypothesis', 'distribution', 'distribution', 'P(D1h', 'discussion', 'framework', 'way', 'behavior', 'algorithm', 'FIND', 'S', 'learning', 'algorithm', 'probability', 'probability', 'distribution', 'P(Dlh', 'algorithm', 'MAP', 'hypothesis', 'assumption', 'algorithm', 'perspective', 'algorithm', 'way', 'spirit', 'bias', 'learner', 'Recall', 'chapter', 'bias', 'algorithm', 'set', 'assumption', 'b', 'inference', 'learner', 'example', 'bias', 'CANDIDATE', 'ELIMINATION', 'algorithm', 'assumption', 'target', 'concept', 'c', 'hypothesis', 'space', 'H.', 'output', 'learning', 'algorithm', 'input', 'bias', 'assumption', 'interpretation', 'way', 'assumption', 'algorithm', 'inference', 'method', 'system', 'reasoning', 'system', 'Bayes', 'assumption', 'learner', 'assumption', 'form', 'probability', 'H', 'distribution', 'P(h', 'strength', 'datum', 'hypothesis', 'P(Dlh', 'definition', 'P(h', 'P(D(h', 'section', 'assumption', 'CANDIDATE', 'ELIMINATION', 'FIND', 'S', 'algorithm', 'reasoning', 'system', 'Bayes', 'theorem', 'output', 'behavior', 'algorithm', 'probability', 'distribution', 'discussion', 'section', 'case', 'reasoning', 'case', 'P(D1h', 'ue', 'prediction', 'hypothesis', 'assumption', 'noise', 'training', 'datum', 'section', 'training', 'datum', 'P(D1h', 'value', 'P(D1h', 'assumption', 'probability', 'distribution', 'noise'], 'difficulty': 'Hard', 'format': 'PDF', 'duration': '19 minutes', 'learning_style': 'Reading/Writing', 'subject': 'ML', 'module': 'M5', 'file_path': '/content/ML-M5.pdf'}\n",
            "{'title': 'DS&A-M4', 'keywords': ['tree', 'mystery', 'Jim', 'Woodring', 'DataSciencester', 'VP', 'Talent', 'number', 'job', 'candidate', 'site', 'degree', 'success', 'data', 'attribute', 'candidate', 'candidate', 'datum', 'model', 'identifying', 'candidate', 'time', 'interview', 'fit', 'decision', 'tree', 'modeling', 'tool', 'data', 'scientist', 'kit', 'Decision', 'Trees', 'MODULE-4', 'decision', 'tree', 'decision', 'tree', 'tree', 'structure', 'number', 'decision', 'path', 'outcome', 'path', 'game', 'Twenty', 'Questions', 'decision', 'tree', 'example', 'animal', 'leg', 'no', 'no', 'back', 'cent', 'coin', 'echidna', 'path', 'leg', 'cent', 'coin', 'Echidna', 'idiosyncratic', 'animal', 'decision', 'tree', 'figure', 'figure', 'animal', 'decision', 'tree', 'decision', 'tree', 'lot', 'process', 'prediction', 'model', 'decision', 'tree', 'mix', 'number', 'leg', 'delicious', 'attribute', 'datum', 'attribute', 'time', 'decision', 'tree', 'set', 'training', 'datum', 'problem', 'tree', 'one', 'data', 'set', 'lot', 'work', 'decision', 'tree', 'training', 'datum', 'datum', 'way', 'people', 'decision', 'tree', 'classification', 'tree', 'output', 'regression', 'tree', 'output', 'chapter', 'classification', 'tree', 'ID3', 'algorithm', 'decision', 'tree', 'set', 'datum', 'decision', 'tree', 'thing', 'problem', 'output', 'candidate', 'website', 'visitor', 'advertisement', 'a', 'advertisement', 'b', 'food', 'office', 'fridge', 'Entropy', 'order', 'decision', 'tree', 'question', 'order', 'stage', 'tree', 'possibility', 'animal', 'leg', 'possibility', 'grasshopper', 'possibility', 'duck', 'question', 'possibility', 'answer', 'question', 'answer', 'lot', 'information', 'tree', 'question', 'answer', 'output', 'answer', 'output', 'vice', 'question', 'question', 'answer', 'information', 'prediction', 'choice', 'notion', 'information', 'entropy', 'disorder', 'uncertainty', 'datum', 'S', 'datum', 'member', 'number', 'class', 'datum', 'point', 'class', 'uncertainty', 'entropy', 'data', 'point', 'class', 'lot', 'uncertainty', 'entropy', 'math', 'term', 'proportion', 'datum', 'class', 'entropy', 'standard', 'convention', 'detail', 'term', 'figure', 'figure', 'graph', 'entropy', 'datum', 'class', '’s', 'datum', 'class', 'behavior', 'function', 'entropy(class_probabilitie', 'list', 'class', 'probability', 'entropy', 'sum(-p', 'p', 'class_probabilitie', 'p', '#', 'probability', 'datum', 'pair', 'input', 'label', 'class', 'label', 'probability', 'probability', 'class_probabilities(labels', '=', 'len(label', 'return', 'count', 'counter(labels).value', 'def', 'data_entropy(labeled_data', 'label', '_', 'label', 'labeled_data', 'probability', 'class_probabilities(labels', 'entropy(probabilitie', 'Entropy', 'Partition', 'entropy', 'uncertainty', 'set', 'datum', 'stage', 'decision', 'tree', 'question', 'answer', 'partition', 'datum', 'subset', 'instance', 'leg', 'question', 'partition', 'animal', 'leg', 'spider', 'echidna', 'notion', 'entropy', 'set', 'datum', 'way', 'partition', 'entropy', 'datum', 'subset', 'entropy', 'entropy', 'subset', 'entropy', 'example', 'cent', 'coin', 'question', 'animal', 'point', '=', 'echidna', '=', 'entropy', 'entropy', 'fraction', 'class', 'datum', 'S', 'subset', 'proportion', 'datum', 'entropy', 'partition', 'sum', 'partition_entropy(subsets', 'entropy', 'partition', 'datum', 'subset', 'subset', 'list', 'list', 'datum', '=', 'sum(len(subset', 'subset', 'subset', 'return', 'sum', 'data_entropy(subset', 'len(subset', 'subset', 'subset', 'note', 'problem', 'approach', 'attribute', 'value', 'entropy', 'overfitting', 'example', 'bank', 'decision', 'tree', 'customer', 'mortgage', 'datum', 'training', 'set', 'datum', 'customer', 'Social', 'Security', 'number', 'SSN', 'person', 'subset', 'entropy', 'model', 'SSN', 'training', 'set', 'reason', 'attribute', 'number', 'value', 'decision', 'tree', 'decision', 'tree', 'VP', 'datum', 'specification', 'input', 'label', 'input', 'dict', 'candidate', 'attribute', 'label', 'candidate', 'False', 'candidate', 'candidate', 'level', 'language', 'Twitter', 'phd', \"level':'senior\", \"lang':'java\", \"'\", 'False', \"level':'senior\", \"lang':'java\", \"'\", \"phd':'yes\", \"'\", 'False', \"'\", \"level':'Mid\", \"lang':'python\", \"'\", \"'\", \"lang':'python\", \"'\", \"'\", \"'\", \"phd':'yes\", \"'\", 'False', \"'\", \"level':'Mid\", \"phd':'yes\", \"'\", \"level':'senior\", \"lang':'python\", \"'\", 'False', \"level':'senior\", \"'\", \"lang':'python\", \"level':'senior\", \"lang':'python\", \"phd':'yes\", \"'\", \"'\", \"level':'Mid\", \"lang':'python\", \"'\", \"phd':'yes\", \"'\", \"'\", \"level':'Mid\", \"lang':'java\", \"'\", \"lang':'python\", \"'\", \"phd':'yes\", \"'\", 'tree', 'decision', 'node', 'question', 'answer', 'leaf', 'node', 'prediction', 'ID3', 'algorithm', 'manner', 'datum', 'list', 'attribute', 'datum', 'label', 'leaf', 'node', 'label', 'list', 'attribute', 'question', 'leaf', 'node', 'label', 'datum', 'attribute', 'partition', 'partition', 'entropy', 'decision', 'node', 'attribute', 'Recur', 'subset', 'attribute', 'algorithm', 'step', 'option', 'data', 'set', 'tree', 'move', 'algorithm', 'place', 'decision', 'tree', 'step', 'data', 'set', 'datum', 'set', 'label', 'attribute', 'step', 'partition', 'entropy', 'function', 'partitioning', 'partition_by(input', 'attribute', 'input', 'pair', 'attribute_dict', 'label', 'dict', '>', 'input', 'group', 'defaultdict(list', 'input', 'input', '=', 'input[0][attribute', '#', 'value', 'attribute', 'groups[key].append(input', '#', 'input', 'list', 'return', 'group', 'entropy', 'def', 'partition_entropy_by(input', 'attribute', 'entropy', 'partition', 'partition', '=', 'partition_by(inputs', 'attribute', 'return', 'partition_entropy(partitions.value', 'entropy', 'partition', 'datum', 'key', \"level','lang','tweets','phd\", 'print', 'key', 'partition_entropy_by(input', '#', 'level', '#', 'lang', '#', '#', 'phd', 'entropy', 'level', 'subtree', 'level', 'value', 'candidate', 'Mid', 'subtree', 'leaf', 'node', 'True', 'candidate', 'mix', 'Trues', 'Falses', 'input', 'label', 'input', 'label', 'input', 'input[\"level', 'key', \"'\", 'lang', \"'\", 'tweet', \"'\", 'phd', 'print', 'key', 'partition_entropy_by(senior_input', '#', 'lang', '#', '#', 'phd', 'split', 'tweet', 'entropy', 'partition', 'level', 'candidate', 'tweet', 'tweet', 'False', 'thing', 'Junior', 'candidate', 'splitting', 'phd', 'phd', 'phd', 'False', 'figure', 'decision', 'tree', 'figure', 'decision', 'tree'], 'difficulty': 'Intermediate', 'format': 'PDF', 'duration': '10 minutes', 'learning_style': 'Reading/Writing', 'subject': 'DS&A', 'module': 'M4', 'file_path': '/content/DS&A-M4.pdf'}\n",
            "{'title': 'ML-M4', 'keywords': ['decision', 'tree', 'Early', 'Release', 'ebook', 'book', 'form', 'author', 'content', 'advantage', 'technology', 'release', 'title', 'following', 'chapter', 'release', 'book', 'SVMs', 'decision', 'tree', 'Machine', 'Learning', 'classification', 'regression', 'task', 'multioutput', 'task', 'algorithm', 'dataset', 'example', 'chap‐', 'ter', 'decisiontreeregressor', 'model', 'California', 'housing', 'dataset', 'decision', 'Trees', 'component', 'Random', 'Forests', 'chap‐', 'ter', 'Machine', 'Learning', 'today', 'chapter', 'visualize', 'predic‐', 'tion', 'decision', 'tree', 'CART', 'training', 'algorithm', 'Scikit', 'Learn', 'tree', 'regression', 'task', 'limitation', 'decision', 'Trees', 'training', 'Decision', 'tree', 'decision', 'tree', 'look', 'pre‐', 'diction', 'code', 'decisiontreeclassifier', 'iris', 'dataset', 'chapter', 'sklearn.dataset', 'import', 'load_iris', 'import', 'decisiontreeclassifier', 'module-4', 'Graphviz', 'source', 'graph', 'visualization', 'software', 'package', 'http://www.graphviz.org/.', 'iris', '=', 'load_iris', 'x', '=', 'iris.data', '#', 'length', 'width', 'y', 'tree_clf', 'DecisionTreeClassifier(max_depth=2', 'tree_clf.fit(X', 'y', 'Decision', 'Tree', 'method', 'graph', 'definition', 'file', 'import', 'export_graphviz', 'tree_clf', '=', 'image_path(\"iris_tree.dot', 'feature_name', '=', 'iris.feature_names[2', ':]', 'class_name', 'iris.target_name', '.dot', 'file', 'variety', 'format', 'PDF', 'PNG', 'dot', 'command', 'line', 'tool', 'graphviz', 'package.1', 'command', 'line', 'convert', '.dot', 'file', '.png', 'image', 'file', 'dot', 'decision', 'tree', 'figure', '|', 'chapter', 'decision', 'tree', 'Figure', 'Iris', 'Decision', 'Tree', 'prediction', 'tree', 'figure', 'prediction', 'iris', 'flower', 'root', 'node', 'depth', 'top', 'node', 'flower', 'length', 'cm', 'root', 'child', 'node', 'depth', 'case', 'leaf', 'node', 'child', 'node', 'question', 'class', 'node', 'Decision', 'Tree', 'flower', 'Iris', 'Setosa', 'class', '=', 'setosa', 'flower', 'time', 'length', 'cm', 'root', 'child', 'node', 'depth', 'leaf', 'node', 'question', 'width', 'cm', 'flower', 'Iris', 'Versicolor', 'depth', 'Iris', 'Virginica', 'depth', 'quality', 'decision', 'Trees', 'datum', 'preparation', 'feature', 'scaling', 'prediction', 'node', 'sample', 'attribute', 'training', 'instance', 'example', 'training', 'instance', 'length', 'cm', 'depth', 'width', 'cm', 'depth', 'node', 'value', 'attribute', 'training', 'instance', 'class', 'node', 'example', 'right', 'node', 'Iris', 'Setosa', 'Versicolor', 'Iris', 'Virginica', 'node', 'gini', 'attribute', 'impur‐', 'ity', 'node', 'gini=0', 'training', 'instance', 'class', 'example', 'depth-1', 'node', 'Iris', 'Setosa', 'training', 'instance', 'gini', 'score', 'equation', 'training', 'algo‐', 'rithm', 'gini', 'score', 'Gi', 'ith', 'node', 'example', 'depth-2', 'node', 'gini', 'score', '≈', 'impurity', 'measure', 'equation', 'gini', 'impurity', 'Gi', 'k', '=', 'pi', 'k', 'pi', 'k', 'ratio', 'class', 'k', 'instance', 'training', 'instance', 'ith', 'node', 'Scikit', 'Learn', 'CART', 'algorithm', 'tree', 'nonleaf', 'node', 'child', 'question', 'answer', 'algorithm', 'ID3', 'decision', 'tree', 'node', 'chil‐', 'dren', 'figure', 'Decision', 'Tree', 'decision', 'boundary', 'line', 'rep‐', 'decision', 'boundary', 'root', 'node', 'depth', 'length', 'cm', 'area', 'Iris', 'Setosa', 'area', 'impure', 'depth-1', 'right', 'node', 'width', 'cm', 'line', 'max_depth', 'Decision', 'Tree', 'max_depth', 'depth-2', 'node', 'decision', 'boundary', 'line', '|', 'chapter', 'decision', 'tree', 'Figure', 'decision', 'Tree', 'decision', 'boundary', 'Model', 'Interpretation', 'White', 'Box', 'Versus', 'Black', 'Box', 'decision', 'tree', 'decision', 'pret', 'model', 'white', 'box', 'model', 'contrast', 'dom', 'forest', 'network', 'box', 'model', 'prediction', 'calculation', 'prediction', 'term', 'prediction', 'example', 'network', 'particu‐', 'person', 'picture', 'prediction', 'model', 'person', 'eye', 'mouth', 'nose', 'shoe', 'couch', 'decision', 'tree', 'classification', 'rule', 'need', 'flower', 'classification', 'Estimating', 'Class', 'Probabilities', 'Decision', 'Tree', 'probability', 'instance', 'class', 'k', 'tree', 'leaf', 'node', 'instance', 'ratio', 'training', 'instance', 'class', 'k', 'node', 'example', 'flower', 'petal', 'cm', 'sponding', 'leaf', 'node', 'depth-2', 'node', 'Decision', 'Tree', 'probability', '%', 'Iris', 'Setosa', '%', 'Iris', 'Versicolor', '%', 'Iris', 'Virginica', 'course', 'class', 'Iris', 'Versicolor', 'class', 'probability', 'tree_clf.predict_proba([[5', 'array([[0', 'Estimating', 'Class', 'Probabilities', '|', 'tree_clf.predict([[5', 'Perfect', 'probability', 'rectangle', 'figure', 'example', 'petal', 'cm', 'cm', 'Iris-', 'Virginica', 'case', 'CART', 'Training', 'Algorithm', 'Scikit', 'Learn', 'Classification', 'Regression', 'Tree', 'CART', 'algorithm', 'decision', 'Trees', 'tree', 'idea', 'algo‐', 'rithm', 'training', 'subset', 'feature', 'k', 'length', '≤', 'cm', 'k', 'tk', 'pair', 'k', 'tk', 'subset', 'size', 'cost', 'function', 'algorithm', 'Equation', 'Equation', 'cart', 'cost', 'function', 'classification', 'J', 'k', '=', 'mleft', 'Gleft', 'mright', 'm', 'Gright', 'Gleft', 'measure', 'impurity', 'subset', 'mleft', 'right', 'number', 'instance', 'subset', 'training', 'subset', 'logic', 'sub', '-', 'subset', 'depth', 'hyperparameter', 'split', 'impurity', 'hyperparameter', 'moment', 'condition', 'min_sam', 'ples_leaf', 'min_weight_fraction_leaf', 'max_leaf_nodes', '|', 'chapter', 'decision', 'tree', 'p', 'set', 'problem', 'time', 'NP', 'set', 'problem', 'solution', 'time', 'NP', 'problem', 'problem', 'NP', 'problem', 'time', 'NP', 'problem', 'NP', 'NP', '-', 'Hard', 'ques‐', 'tion', 'P', '=', 'NP', 'p', 'NP', 'algorithm', 'NP', 'problem', 'quantum', 'computer', 'log2', 'logarithm', 'log2(m', 'log(2', 'reduction', 'entropy', 'information', 'gain', 'CART', 'algorithm', 'algorithm', 'split', 'level', 'process', 'level', 'split', 'impurity', 'level', 'algorithm', 'solution', 'solution', 'tree', 'NP-', 'Complete', 'problem:2', 'time', 'prob‐', 'lem', 'training', 'set', 'solution', 'Computational', 'Complexity', 'prediction', 'Decision', 'Tree', 'root', 'leaf', 'decision', 'Trees', 'Decision', 'Tree', 'o(log2(m', 'node', 'value', 'feature', 'prediction', 'complexity', 'o(log2(m', 'number', 'feature', 'prediction', 'deal‐', 'ing', 'training', 'set', 'training', 'algorithm', 'feature', 'max_feature', 'sample', 'node', 'result', 'training', 'complexity', '×', 'm', 'training', 'set', 'instance', 'Scikit', 'Learn', 'training', 'datum', 'presort', '=', 'training', 'con‐', 'training', 'set', 'Gini', 'Impurity', 'Entropy', 'default', 'Gini', 'impurity', 'measure', 'entropy', 'impurity', 'measure', 'criterion', 'hyperparameter', 'concept', 'entropy', 'thermodynamic', 'measure', 'disorder', 'entropy', 'approach', 'molecule', 'variety', 'domain', 'Shannon', 'information', 'theory', 'information', 'content', 'message:4', 'entropy', 'message', 'Machine', 'Learning', 'impurity', 'measure', 'set', 'Computational', 'Complexity', '|', 'Sebastian', 'Raschka', 'analysis', 'detail', 'entropy', 'instance', 'class', 'equation', 'definition', 'entropy', 'ith', 'node', 'example', 'depth-2', 'node', 'Figure', 'entropy', '−49', 'log2', 'log2', '≈', 'Equation', 'Entropy', '−', 'k', '=', 'pi', 'k', 'pi', 'k', 'log2', 'pi', 'k', 'Gini', 'impurity', 'entropy', 'truth', 'time', 'difference', 'tree', 'gini', 'impurity', 'default', 'Gini', 'impurity', 'class', 'branch', 'tree', 'entropy', 'trees.5', 'Regularization', 'Hyperparameters', 'Decision', 'Trees', 'assumption', 'training', 'datum', 'lin‐', 'ear', 'model', 'datum', 'example', 'tree', 'structure', 'training', 'datum', 'model', 'nonparametric', 'model', 'parameter', 'lot', 'number', 'parameter', 'training', 'model', 'structure', 'datum', 'contrast', 'model', 'model', 'number', 'parameter', 'degree', 'freedom', 'risk', 'risk', 'underfitting', 'training', 'datum', 'Decision', 'Tree', 'freedom', 'training', 'regularization', 'regularization', 'hyperparameter', 'algorithm', 'depth', 'Decision', 'Tree', 'Scikit', 'Learn', 'hyperparameter', 'default', 'value', 'none', 'max_depth', 'model', 'risk', 'class', 'parameter', 'shape', 'Decision', 'Tree', 'number', 'sam‐', 'node', 'min_samples_leaf', 'num‐', 'ber', 'sample', 'leaf', 'node', 'min_weight_fraction_leaf', 'min_samples_leaf', 'fraction', 'number', '|', 'chapter', 'decision', 'tree', 'instance', 'max_leaf_node', 'number', 'leaf', 'node', 'max_feature', 'number', 'feature', 'splitting', 'node', 'Increas‐', 'ing', 'min', '_', '*', 'hyperparameter', 'max', '_', 'hyperparameter', 'model', 'algorithm', 'work', 'Decision', 'Tree', 'restriction', 'deleting', 'nodes', 'node', 'child', 'leaf', 'node', 'purity', 'improvement', 'stan‐', 'test', 'χ2', 'test', 'probability', 'improvement', 'result', 'chance', 'hypothesis', 'probability', 'value', 'threshold', '%', 'hyperparameter', 'node', 'child', 'pruning', 'node', 'figure', 'decision', 'Trees', 'moon', 'chapter', 'left', 'Decision', 'Tree', 'default', 'hyperparameter', 'restriction', 'right', 'Decision', 'Tree', 'ples_leaf=4', 'model', 'left', 'model', 'right', 'figure', 'regularization', 'min_samples_leaf', 'Regression', 'Decision', 'Trees', 'regression', 'task', 'regres‐', 'sion', 'tree', 'Scikit', 'Learn', 'DecisionTreeRegressor', 'class', 'dataset', 'max_depth=2', 'import', 'decisiontreeregressor', 'Regression', '|', 'tree_reg', '=', 'DecisionTreeRegressor(max_depth=2', 'tree_reg.fit(X', 'y', 'tree', 'figure', 'figure', 'decision', 'Tree', 'regression', 'tree', 'classification', 'tree', 'differ‐', 'ence', 'class', 'node', 'value', 'example', 'prediction', 'instance', 'x1', '=', 'tree', 'root', 'leaf', 'node', 'value=0.1106', 'prediction', 'target', 'value', 'training', 'instance', 'leaf', 'node', 'prediction', 'Mean', 'Squared', 'Error', 'MSE', 'instance', 'model', 'prediction', 'left', 'figure', 'max_depth=3', 'prediction', 'right', 'pre‐', 'value', 'region', 'target', 'value', 'instance', 'region', 'algorithm', 'region', 'way', 'training', 'instance', 'value', '|', 'chapter', 'decision', 'tree'], 'difficulty': 'Intermediate', 'format': 'PDF', 'duration': '13 minutes', 'learning_style': 'Reading/Writing', 'subject': 'ML', 'module': 'M4', 'file_path': '/content/ML-M4.pdf'}\n",
            "{'title': 'DS&A-M1', 'keywords': ['joke', 'data', 'scientist', 'statistic', 'computer', 'scientist', 'computer', 'science', 'statistician', 'joke', 'fact', 'datum', 'scientist', 'purpose', 'statistician', 'other', 'software', 'engineer', 'machine', 'expert', 'other', 'machine', 'way', 'kindergarten', 'PhDs', 'publication', 'record', 'other', 'paper', 'shame', 'datum', 'science', 'practitioner', 'definition', 'data', 'scientist', 'insight', 'datum', 'today', 'world', 'people', 'datum', 'insight', 'instance', 'site', 'OkCupid', 'member', 'thousand', 'question', 'order', 'match', 'result', 'question', 'date', 'Facebook', 'hometown', 'location', 'friend', 'location', 'migration', 'pattern', 'fanbase', 'football', 'team', 'retailer', 'Target', 'purchase', 'interaction', 'store', 'datum', 'model', 'customer', 'market', 'baby', 'purchase', 'Obama', 'campaign', 'dozen', 'datum', 'scientist', 'data', 'way', 'voter', 'attention', 'donor', 'fundraising', 'appeal', 'program', 'vote', 'effort', 'effort', 'role', 'president', 're', '-', 'election', 'bet', 'campaign', 'future', 'data', 'arm', 'race', 'datum', 'science', 'datum', 'collection', 'datum', 'scientist', 'skill', 'datum', 'government', 'health', 'career', 'way', 'people', 'advertisement', 'Data', 'Science', 'MODULE-1', 'Motivating', 'Hypothetical', 'DataSciencester', 'Congratulations', 'datum', 'science', 'effort', 'DataSciencester', 'network', 'datum', 'scientist', 'datum', 'scientist', 'DataSciencester', 'datum', 'science', 'practice', 'fairness', 'DataSciencester', 'product', 'job', 'book', 'datum', 'science', 'concept', 'problem', 'work', 'datum', 'user', 'datum', 'interaction', 'site', 'datum', 'experiment', 'DataSciencester', 'mentality', 'tool', 'scratch', 'end', 'understanding', 'fundamental', 'datum', 'science', 'skill', 'company', 'premise', 'problem', 'luck', 'jean', 'Fridays', 'bathroom', 'hall', 'right', 'Key', 'Connectors', 'day', 'job', 'DataSciencester', 'VP', 'Networking', 'question', 'user', 'one', 'connector', 'datum', 'scientist', 'end', 'dump', 'DataSciencester', 'network', 'life', 'people', 'datum', 'chapter', 'datum', 'datum', 'list', 'user', 'dict', 'user', 'i', 'd', 'number', 'name', 'coincidence', 'user', 'i', 'd', 'user', 'i', 'd', 'name', 'Hero', 'i', 'd', 'name', 'Dunn', 'i', 'd', 'name', 'Sue', 'i', 'd', 'name', 'Chi', 'i', 'd', 'name', 'Thor', 'i', 'd', 'name', 'clive', 'i', 'd', 'name', 'Hicks', 'i', 'd', 'name', 'Devin', 'i', 'd', 'name', 'Kate', 'i', 'd', 'name', 'Klein', 'friendship', 'datum', 'list', 'pair', 'id', 'friendship', 'example', 'tuple', 'data', 'scientist', 'i', 'd', 'Hero', 'datum', 'scientist', 'i', 'd', 'Dunn', 'friend', 'network', 'figure', 'figure', 'DataSciencester', 'network', 'user', 'dict', 'datum', 'NOTE', 'detail', 'code', 'chapter', 'crash', 'course', 'Python', 'flavor', 'example', 'list', 'friend', 'user', 'user', 'friend', 'property', 'list', 'user', 'user', 'list', 'friendship', 'datum', 'j', 'friendship', '#', 'user', 'i', 'd', '#', 'friend', 'j', '#', 'j', 'friend', 'user', 'dict', 'list', 'friend', 'question', 'graph', 'number', 'connection', 'number', 'connection', 'length', 'friend', 'number_of_friends(user', 'friend', 'user', '_', 'len(user[\"friend', '#', 'length', 'friend_id', 'list', 'total_connection', '=', 'sum(number_of_friends(user', 'user', 'user', 'number', 'user', '_', 'future', 'import', 'division', '#', 'integer', 'division', 'num_user', '=', 'len(user', '#', 'length', 'user', 'list', 'avg_connection', 'total_connection', 'people', 'people', 'number', 'friend', 'user', 'friend', 'friend', '#', 'list', 'user_id', 'number_of_friends', 'num_friends_by_id', 'user[\"id', 'number_of_friends(user', 'user', 'user', 'sorted(num_friends_by_id', '#', 'user_id', 'num_friends', 'num_friend', '#', 'num_friend', 'reverse', '#', '#', 'pair', 'user_id', 'num_friends', '#', '#', 'way', 'way', 'people', 'network', 'fact', 'network', 'degree', 'centrality', 'figure', 'figure', 'DataSciencester', 'network', 'degree', 'virtue', 'result', 'example', 'DataSciencester', 'network', 'Thor', 'i', 'd', 'connection', 'Dunn', 'i', 'd', 'network', 'Thor', 'chapter', 'network', 'detail', 'notion', 'centrality', 'intuition', 'Data', 'Scientists', 'hire', 'paperwork', 'VP', 'Fraternization', 'desk', 'connection', 'member', 'Data', 'Scientists', 'suggester', 'instinct', 'user', 'friend', 'friend', 'user', 'friend', 'person', 'friend', 'result', 'def', 'friends_of_friend_ids_bad(user', '#', 'friend', 'friend', 'return', 'friend', 'user[\"friend', '#', 'user', 'friend', 'foaf', 'friend[\"friend', '#', '_', 'friend', 'users[0', 'Hero', 'user', 'Hero', 'friend', 'friend', 'user', 'friend', 'Hero', 'user', 'Chi', 'friend', 'print', 'friend', '#', 'print', 'friend', '#', 'print', 'friend', '#', 'people', 'friend', 'friend', 'way', 'information', 'count', 'friend', 'helper', 'function', 'people', 'user', 'collection', 'import', 'Counter', '#', 'default', 'def', 'not_the_same(user', 'user', 'ids', 'user[\"id', '=', 'other_user[\"id', 'def', 'not_friends(user', 'friend', 'user[\"friend', 'people', 'user[\"friend', 'friend', 'user[\"friend', 'return', 'Counter(foaf[\"id', 'friend', 'user[\"friend', '#', 'friend', 'foaf', 'friend[\"friend', '#', '*', 'friend', '#', 'not_friends(user', 'foaf', '#', 'friend', 'print', 'friends_of_friend_ids(users[3', '#', 'Counter({0', 'Chi', 'i', 'd', 'friend', 'Hero', 'i', 'd', 'friend', 'Clive', 'i', 'd', 'data', 'scientist', 'user', 'interest', 'example', 'expertise', 'aspect', 'datum', 'science', 'hand', 'datum', 'list', 'pair', 'user_id', 'interest', 'interest', 'hadoop', 'Big', 'Data', 'HBase', 'Java', 'Spark', 'storm', 'Cassandra', 'NoSQL', 'Cassandra', 'HBase', 'Postgres', 'Python', 'scikit', 'learn', 'statsmodel', 'panda', 'r', 'Python', 'statistic', 'regression', 'probability', 'machine', 'learning', 'regression', 'decision', 'tree', 'libsvm', 'Python', 'r', 'Java', 'C++', 'Haskell', 'programming', 'language', 'statistic', 'probability', 'mathematic', 'theory', 'machine', 'learning', 'scikit', 'learn', 'Mahout', 'network', 'network', 'learning', 'Big', 'Data', 'intelligence', 'hadoop', 'Java', 'MapReduce', 'Big', 'Data', 'example', 'Thor', 'i', 'd', 'friend', 'Devin', 'i', 'd', 'interest', 'machine', 'learning', 'function', 'user', 'interest', 'def', 'return', 'user_id', 'user_id', 'interest', 'list', 'interest', 'search', 'lot', 'user', 'interest', 'lot', 'search', 'index', 'interest', 'user', 'collection', 'import', 'defaultdict', '#', 'key', 'interest', 'value', 'list', 'user_ids', 'interest', '=', 'defaultdict(list', 'user_id', 'interest', 'interest', 'user_ids_by_interest[interest].append(user_id', 'user', 'interest', '#', 'key', 'user_id', 'value', 'list', 'interest', 'user_id', 'interests_by_user_id', '=', 'defaultdict(list', 'user_id', 'interest', 'interest', 'interest', 'user', 'Iterate', 'user', 'interest', 'interest', 'user', 'interest', 'count', 'time', 'user', 'most_common_interests_with(user', 'return', 'Counter(interested_user_id', 'interest', 'interested_user_id', 'interested_user_id', 'user[\"id', 'Data', 'Scientists', 'feature', 'combination', 'friend', 'interest', 'kind', 'application', 'chapter', 'Salaries', 'experience', 'lunch', 'VP', 'Public', 'Relations', 'fun', 'fact', 'datum', 'scientist', 'salary', 'datum', 'course', 'datum', 'user', 'salary', 'dollar', 'tenure', 'data', 'scientist', 'year', 'salaries_and_tenure', 'step', 'datum', 'chapter', 'result', 'Figure', 'figure', 'salary', 'year', 'experience', 'people', 'experience', 'fact', 'idea', 'salary', 'tenure', '#', 'key', 'year', 'value', 'list', 'salary', 'tenure', 'salary_by_tenure', '=', 'defaultdict(list', 'salary', 'tenure', 'salaries_and_tenure', 'salary_by_tenure[tenure].append(salary', '#', 'key', 'year', 'value', 'salary', 'tenure', 'average_salary_by_tenure', '=', 'tenure', 'len(salarie', 'tenure', 'salary', 'salary_by_tenure.item', 'none', 'user', 'tenure', 'user', 'salary', 'tenure', 'tenure_bucket(tenure', 'tenure', 'tenure', 'return', 'group', 'salary', 'bucket', '#', 'key', 'tenure', 'bucket', 'value', 'list', 'salary', 'bucket', 'salary_by_tenure_bucket', '=', 'defaultdict(list', 'salary', 'tenure', 'salaries_and_tenure', '=', 'tenure_bucket(tenure', 'salary_by_tenure_bucket[bucket].append(salary', 'salary', 'group', '#', 'key', 'tenure', 'bucket', 'value', 'salary', 'bucket', 'tenure_bucket', 'len(salarie', 'tenure_bucket', 'salary', 'salary_by_tenure_bucket.iteritem', 'soundbite', 'datum', 'scientist', 'year', 'experience', 'earn', '%', 'datum', 'scientist', 'experience', 'bucket', 'way', 'sort', 'statement', 'salary', 'effect', 'year'], 'difficulty': 'Intermediate', 'format': 'PDF', 'duration': '12 minutes', 'learning_style': 'Reading/Writing', 'subject': 'DS&A', 'module': 'M1', 'file_path': '/content/DS&A-M1.pdf'}\n",
            "{'title': 'ML-M1', 'keywords': ['Machine', 'Learning', 'Machine', 'Learning', 'Landscape', 'Machine', 'learning', 'Machine', 'Learning', 'science', 'art', 'programming', 'computer', 'datum', 'Arthur', 'Samuel', 'Machine', 'Learning', 'field', 'study', 'computer', 'ability', 'Tom', 'Mitchell', 'computer', 'program', 'experience', 'e', 'respect', 'task', 'T', 'performance', 'measure', 'p', 'performance', 'T', 'p', 'experience', 'E.', 'example', 'spam', 'filter', 'Machine', 'Learning', 'program', 'spam', 'example', 'spam', 'email', 'user', 'example', 'email', 'example', 'system', 'training', 'set', 'training', 'example', 'training', 'instance', 'sample', 'case', 'task', 'T', 'spam', 'email', 'experience', 'E', 'training', 'datum', 'performance', 'measure', 'p', 'example', 'ratio', 'email', 'performance', 'measure', 'accuracy', 'classification', 'task', 'Use', 'Machine', 'learning', 'Machine', 'Learning', 'problem', 'solution', 'lot', 'hand', 'tuning', 'list', 'rule', 'Machine', 'Learning', 'algorithm', 'code', 'problem', 'solution', 'approach', 'Machine', 'Learning', 'technique', 'solution', 'Fluctuating', 'environment', 'Machine', 'Learning', 'system', 'datum', 'insight', 'problem', 'amount', 'datum', 'MODULE', 'introduction', 'Machine', 'Learning', '21AI63', 'Example', 'filtering', 'spam', 'filter', 'program', 'programming', 'technique', 'figure', 'spam', 'word', 'phrase', '4u', 'credit', 'card', 'lot', 'subject', 'pattern', 'sender', 'name', 'email', 'body', 'detection', 'algorithm', 'pattern', 'program', 'email', 'spam', 'number', 'pattern', 'program', 'step', 'problem', 'program', 'list', 'rule', 'spam', 'filter', 'Machine', 'Learning', 'technique', 'word', 'phrase', 'predictor', 'spam', 'pattern', 'word', 'spam', 'example', 'ham', 'example', 'figure', 'program', 'machine', 'learning', 'spam', 'filter', 'adapt', 'spam', 'tactic', 'pattern', 'u', 'rule', 'update', 'approach', 'time', 'effort', 'effectiveness', 'spam', 'technique', 'Machine', 'Learning', '21AI63', 'area', 'Machine', 'Learning', 'problem', 'approach', 'algorithm', 'Example', 'speech', 'recognition', 'program', 'word', 'word', 'pitch', 'sound', 'T', 'algorithm', 'pitch', 'sound', 'intensity', 'one', 'twos', 'technique', 'thousand', 'word', 'million', 'people', 'environment', 'dozen', 'language', 'solution', 'algorithm', 'example', 'recording', 'word', 'Machine', 'Learning', 'human', 'figure', 'ML', 'algorithm', 'correlation', 'trend', 'understanding', 'problem', 'Machine', 'Learning', 'Types', 'Machine', 'type', 'Machine', 'Learning', 'system', 'category', 'supervision', 'learning', 'learning', 'reinforcement', 'fly', 'learning', 'batch', 'datum', 'point', 'datum', 'point', 'pattern', 'training', 'datum', 'model', 'Instance', 'learning', 'model', 'learning', 'Machine', 'Learning', 'system', 'amount', 'type', 'supervision', 'training', 'category', 'learning', 'learning', 'reinforcement', 'learning', 'learning', 'training', 'datum', 'feed', 'algorithm', 'solution', 'label', 'learning', 'task', 'Classification', 'spam', 'filter', 'example', 'classification', 'example', 'email', 'class', 'spam', 'ham', 'email', 'Machine', 'Learning', '21AI63', 'learning', 'task', 'regression', 'task', 'target', 'value', 'price', 'car', 'set', 'feature', 'mileage', 'age', 'brand', 'predictor', 'sort', 'task', 'regression', 'figure', '•', 'system', 'example', 'car', 'predictor', 'label', 'price', 'learning', '•', 'k', 'Nearest', 'Neighbors', 'Linear', 'Regression', 'Logistic', 'regression', 'Support', 'Vector', 'Machines', 'SVMs', 'decision', 'Trees', 'Random', 'Forests', 'network', 'learning', 'training', 'datum', 'figure', 'system', 'teacher', 'learning', 'algorithm', 'k', 'Means', 'DBSCAN', 'Hierarchical', 'Cluster', 'Analysis', 'HCA', 'Anomaly', 'detection', 'detection', 'class', 'SVM', 'Isolation', 'Forest', 'Eclat', 'Visualization', 'dimensionality', 'reduction', 'Principal', 'Component', 'Analysis', 'PCA', 'Kernel', 'PCA', 'Linear', 'LLE', 't', 'Stochastic', 'Neighbor', 't', 'SNE', 'Association', 'rule', 'Apriori', 'Eclat', 'Machine', 'Learning', '21AI63', 'example', 'datum', 'blog', 'visitor', 'algorithm', 'group', 'visitor', 'figure', 'algorithm', 'group', 'visitor', '•', '%', 'visitor', 'male', 'book', 'blog', 'evening', '%', 'sci', 'fi', 'lover', 'weekend', 'clustering', 'algorithm', 'group', 'group', 'post', 'group', 'learning', 'algorithm', 'training', 'datum', 'lot', 'datum', 'bit', 'datum', 'learning', 'figure', 'example', 'Google', 'photo', 'user', 'family', 'photo', 'service', 'person', 'a', 'photo', 'person', 'b', 'photo', 'part', 'algorithm', 'clustering', 'system', 'need', 'user', 'people', 'label', 'person', 'photo', 'photo', 'Machine', 'Learning', '21AI63', 'Reinforcement', 'Learning', 'learning', 'system', 'agent', 'context', 'environment', 'action', 'reward', 'return', 'penalty', 'form', 'reward', 'figure', 'strategy', 'policy', 'reward', 'time', 'policy', 'action', 'agent', 'situation', 'example', 'robot', 'Reinforcement', 'Learning', 'DeepMind', 'alphago', 'program', 'example', 'Reinforcement', 'Machine', 'Learning', 'system', 'system', 'stream', 'datum', 'batch', 'learning', 'batch', 'learning', 'system', 'datum', 'lot', 'time', 'resource', 'offline', 'system', 'production', 'run', 'Batch', 'learning', 'Machine', 'Learning', '21AI63', 'desire', 'batch', 'system', 'datum', 'version', 'system', 'scratch', 'dataset', 'system', 'process', 'training', 'Machine', 'Learning', 'system', 'batch', 'learning', 'system', 'datum', 'version', 'system', 'scratch', 'solution', 'training', 'set', 'datum', 'hour', 'system', 'hour', 'system', 'datum', 'stock', 'price', 'reactive', 'solution', 'learning', 'system', 'datum', 'group', 'mini', '-', 'batch', 'learning', 'step', 'system', 'datum', 'fly', 'figure', 'Online', 'learning', 'system', 'datum', 'flow', 'stock', 'price', 'resource', 'learning', 'system', 'datum', 'instance', 'option', 'amount', 'space', 'Online', 'learning', 'algorithm', 'system', 'dataset', 'machine', 'memory', 'core', 'learning', 'algorithm', 'part', 'datum', 'training', 'step', 'data', 'process', 'datum', 'parameter', 'learning', 'system', 'datum', 'learning', 'rate', 'learning', 'rate', 'system', 'datum', 'datum', 'Machine', 'Learning', 'way', 'Machine', 'Learning', 'system', 'approach', 'generalization', 'Instance', 'learning', 'system', 'example', 'case', 'example', 'similarity', 'measure', 'example', 'Figure', 'instance', 'triangle', 'majority', 'instance', 'class', 'Machine', 'Learning', '21AI63', 'model', 'learning', 'model', 'set', 'example', 'model', 'prediction', 'model', 'learning', 'challenge', 'Machine', 'learning', 'ML', 'task', 'algorithm', 'datum', 'thing', 'algorithm', 'datum', 'challenge', 'ML', 'Quantity', 'Training', 'Data', 'Nonrepresentative', 'Training', 'Data', 'Quality', 'Data', 'Irrelevant', 'Features', 'Training', 'Data', 'Training', 'Data', 'testing', 'hyperparameter', 'Tuning', 'Model', 'Selection', 'Quantity', 'Training', 'Data', 'Machine', 'Learning', 'lot', 'datum', 'ML', 'problem', 'thousand', 'example', 'problem', 'image', 'speech', 'recognition', 'million', 'example', 'Nonrepresentative', 'Training', 'Data', 'order', 'training', 'datum', 'case', 'training', 'set', 'model', 'prediction', 'Quality', 'Data', 'training', 'datum', 'error', 'outlier', 'noise', 'quality', 'measurement', 'system'], 'difficulty': 'Intermediate', 'format': 'PDF', 'duration': '10 minutes', 'learning_style': 'Reading/Writing', 'subject': 'ML', 'module': 'M1', 'file_path': '/content/ML-M1.pdf'}\n",
            "{'title': 'ML-M3', 'keywords': ['training', 'Models', 'Early', 'Release', 'ebook', 'book', 'form', 'author', 'content', 'advantage', 'technology', 'release', 'title', 'following', 'chapter', 'release', 'book', 'Machine', 'Learning', 'model', 'training', 'box', 'exercise', 'chapter', 'any‐', 'thing', 'hood', 'regression', 'system', 'digit', 'image', 'classifier', 'spam', 'classifier', 'scratch', 'situation', 'implementation', 'detail', 'understanding', 'thing', 'model', 'training', 'algorithm', 'set', 'hyperparameter', 'task', 'hood', 'issue', 'error', 'analysis', 'top‐', 'ic', 'chapter', 'understanding', 'building', 'network', 'Part', 'book', 'chapter', 'Linear', 'Regression', 'model', 'model', 'way', 'form', 'equation', 'model', 'parame‐', 'ter', 'model', 'training', 'model', 'parameter', 'cost', 'function', 'training', 'set', 'MODULE-3', 'optimization', 'approach', 'Gradient', 'Descent', 'GD', 'model', 'parameter', 'cost', 'function', 'training', 'set', 'set', 'parameter', 'method', 'variant', 'Gradient', 'Descent', 'network', 'Part', 'II', 'Batch', 'GD', 'Mini', '-', 'batch', 'GD', 'Stochastic', 'GD', 'Polynomial', 'Regression', 'model', 'dataset', 'model', 'parameter', 'Linear', 'Regression', 'training', 'datum', 'case', 'curve', 'zation', 'technique', 'risk', 'training', 'set', 'model', 'classification', 'task', 'Logistic', 'Regression', 'Softmax', 'Regression', 'math', 'equation', 'chapter', 'notion', 'linear', 'algebra', 'calculus', 'tion', 'vector', 'matrix', 'derivative', 'concept', 'algebra', 'calculus', 'tutorial', 'Jupyter', 'notebook', 'material', 'mathematic', 'chapter', 'equation', 'text', 'concept', 'Linear', 'Regression', 'chapter', 'regression', 'model', 'life', 'satisfaction', 'life_satisfac‐', 'tion', '=', 'θ0', 'θ1', 'gdp_per_capita', 'model', 'function', 'input', 'feature', 'GDP_per_capita', 'θ0', 'θ1', 'model', 'parameter', 'model', 'prediction', 'sum', 'input', 'feature', 'constant', 'bias', 'term', 'intercept', 'term', 'equation', 'equation', 'Linear', 'Regression', 'model', 'prediction', 'y', 'θ0', 'θ1x1', '⋯+', 'θnxn', 'ŷ', 'value', '|', 'chapter', 'training', 'Models', '•', 'number', 'feature', 'ith', 'feature', 'value', 'θj', 'jth', 'model', 'parameter', 'bias', 'term', 'θ0', 'feature', 'weight', 'θ1', 'θ2', '⋯', 'θn', 'form', 'equa‐', 'tion', 'Equation', 'Linear', 'Regression', 'model', 'prediction', 'form', 'y', '=', 'hθ', 'x', '=', '•', 'θ', 'model', 'parameter', 'vector', 'bias', 'term', 'θ0', 'feature', 'θ1', 'θn', 'instance', 'feature', 'vector', 'x0', 'xn', 'x0', 'θ', 'dot', 'product', 'vector', 'θ', 'x', 'course', 'θ0x0', 'θ1x1', '⋯+', 'θnxn', 'hθ', 'hypothesis', 'function', 'model', 'parameter', 'θ', 'Machine', 'Learning', 'vector', 'column', 'tor', '2D', 'array', 'column', 'θ', 'col‐', 'umn', 'vector', 'prediction', 'y', '=', 'θtx', 'θT', 'transpose', 'θ', 'row', 'vector', 'column', 'vector', 'matrix', 'multiplication', 'θT', 'x.', 'course', 'pre‐', 'diction', 'cell', 'matrix', 'value', 'book', 'notation', 'switching', 'dot', 'product', 'matrix', 'multiplication', 'Linear', 'Regression', 'model', 'model', 'parameter', 'model', 'training', 'set', 'purpose', 'measure', 'model', 'training', 'datum', 'chapter', 'performance', 'measure', 'regression', 'model', 'Root', 'Mean', 'Square', 'Error', 'RMSE', 'equation', 'fore', 'Linear', 'Regression', 'model', 'value', 'θ', 'minimi‐', 'RMSE', 'practice', 'Mean', 'Square', 'Error', 'MSE', 'Linear', 'Regression', '|', 'case', 'algorithm', 'function', 'performance', 'measure', 'model', 'function', 'differentiation', 'property', 'performance', 'measure', 'lack', 'model', 'training', 'regularization', 'demonstration', 'value', 'θ', 'cost', 'function', 'scope', 'book', 'RMSE', 'result', 'value', 'function', 'root).1', 'mse', 'Linear', 'Regression', 'hypothesis', 'hθ', 'training', 'X', 'Equation', 'equation', 'mse', 'cost', 'function', 'Linear', 'Regression', 'model', 'MSE', 'X', 'hθ', '=', 'm', 'notation', 'chapter', 'notation', 'page', 'difference', 'order', 'model', 'vector', 'θ', 'notation', 'mse(θ', 'MSE(X', 'hθ', 'Normal', 'equation', 'value', 'θ', 'cost', 'function', 'form', 'solution', 'word', 'equation', 'result', 'Normal', 'Equation', 'equation', 'equation', 'Normal', 'Equation', 'θ', '=', '−1', 'XT', 'y', '•', 'θ', 'value', 'θ', 'cost', 'function', '•', 'y', 'vector', 'target', 'value', 'y(1', 'y(m', 'datum', 'equation', 'figure', 'import', 'numpy', 'x', '=', 'y', '*', 'x', '|', 'chapter', 'training', 'Models', 'figure', 'linear', 'dataset', 'θ', 'Normal', 'Equation', 'inv', 'function', 'NumPy', 'Linear', 'Algebra', 'module', 'np.linalg', 'inverse', 'matrix', 'dot', 'method', 'matrix', 'multiplication', 'X_b', '=', 'X', '#', 'x0', 'instance', '=', 'np.linalg.inv(X_b', 'T.dot(X_b)).dot(X_b', 'function', 'datum', 'y', '=', '3x1', 'Gaussian', 'noise', 'equation', 'array([[4.21509616', 'θ0', 'θ1', 'θ0', 'θ1', 'noise', 'parameter', 'function', 'prediction', 'θ', 'X_new', '=', 'np.array([[0', 'X_new_b', '=', 'np.c_[np.ones((2', '#', 'x0', 'instance', '=', 'X_new_b.dot(theta_best', 'y_predict', 'array([[4.21509616', 'model', 'prediction', 'figure', 'plt.plot(X', 'y', 'b.', 'Linear', 'Regression', '|', 'note', 'Scikit', 'Learn', 'bias', 'term', '_', 'feature', 'weight', 'coef', '_', 'plt.axis([0', 'plt.show', 'figure', 'Linear', 'Regression', 'model', 'prediction', 'regression', 'Scikit', 'Learn', 'sklearn.linear_model', 'import', 'LinearRegression', 'lin_reg', 'LinearRegression', 'lin_reg.fit(X', 'y', 'lin_reg.intercept', '_', 'lin_reg.coef', '_', 'array([[2.77011339', 'lin_reg.predict(X_new', 'array([[4.21509616', 'LinearRegression', 'class', 'scipy.linalg.lstsq', 'function', 'name', 'square', 'theta_best_svd', 'residual', 'rank', 's', 'np.linalg.lstsq(X_b', 'y', 'theta_best_svd', 'array([[4.21509616', 'function', 'θ', '=', 'X+y', '�', '+', 'pseudoinverse', 'X', 'Moore', 'Penrose', 'inverse', 'np.linalg.pinv', 'pseudoin‐', 'verse', 'np.linalg.pinv(X_b).dot(y', 'array([[4.21509616', '|', 'chapter', 'training', 'Models', 'pseudoinverse', 'matrix', 'factorization', 'technique', 'Singular', 'Value', 'Decomposition', 'SVD', 'training', 'matrix', 'x', 'matrix', 'multiplication', 'matrix', 'U', 'Σ', 'VT', 'numpy.linalg.svd', 'pseudoinverse', 'X+', 'VΣ+UT', 'matrix', 'algorithm', 'Σ', 'value', 'threshold', 'value', 'value', 'inverse', 'matrix', 'approach', 'Normal', 'Equation', 'edge', 'case', 'Normal', 'Equation', 'matrix', 'XTX', 'm', 'feature', 'pseudoinverse', 'Computational', 'Complexity', 'Normal', 'Equation', 'inverse', 'XT', 'X', '×', 'matrix', 'n', 'number', 'feature', 'complexity', 'inverting', 'matrix', 'O(n2.4', 'O(n3', 'implementation', 'word', 'number', 'feature', 'computation', 'time', 'SVD', 'approach', 'Scikit', 'Learn', 'LinearRegression', 'class', 'number', 'feature', 'computation', 'time', 'Normal', 'Equation', 'SVD', 'approach', 'number', 'feature', 'side', 'regard', 'number', 'instan‐', 'ce', 'training', 'training', 'set', 'memory', 'Linear', 'Regression', 'model', 'equa‐', 'tion', 'algorithm', 'prediction', 'complexity', 'regard', 'number', 'instance', 'prediction', 'number', 'feature', 'word', 'prediction', 'instance', 'feature', 'time', 'way', 'Linear', 'Regression', 'model', 'case', 'number', 'feature', 'training', 'instance', 'memory', 'Gradient', 'Descent', 'Gradient', 'Descent', 'optimization', 'algorithm', 'solution', 'range', 'problem', 'idea', 'Gradient', 'Descent', 'parameter', 'order', 'cost', 'function', 'Gradient', 'Descent', '|', 'mountain', 'fog', 'slope', 'ground', 'foot', 'strategy', 'bottom', 'valley', 'direction', 'slope', 'Gradient', 'Descent', 'gradient', 'error', 'function', 'regard', 'parameter', 'vector', 'θ', 'direction', 'gradient', 'gra‐', 'dient', 'minimum', 'value', 'initializa‐', 'tion', 'baby', 'step', 'time', 'step', 'cost', 'function', 'mse', 'algorithm', 'minimum', 'figure', 'figure', 'Descent', 'parameter', 'Gradient', 'Descent', 'size', 'step', 'learning', 'rate', 'hyperparameter', 'learning', 'rate', 'algorithm', 'iteration', 'time', 'figure', '|', 'chapter', 'training', 'Models', 'figure', 'learning', 'rate', 'hand', 'learning', 'rate', 'valley', 'side', 'algorithm', 'diverge', 'value', 'solution', 'figure', 'figure', 'learning', 'rate', 'cost', 'function', 'bowl', 'hole', 'ridge', 'plateaus', 'sort', 'terrain', 'convergence', 'minimum', 'figure', 'challenge', 'Gradient', 'Descent', 'ran‐', 'dom', 'initialization', 'algorithm', 'left', 'mini‐', 'mum', 'minimum', 'right', 'time', 'plateau', 'minimum', 'Gradient', 'Descent', '|', 'derivative', 'Lipschitz', 'feature', 'change', 'θ1', 'cost', 'function', 'bowl', 'θ1', 'figure', 'Gradient', 'Descent', 'pitfall', 'mse', 'cost', 'function', 'Linear', 'Regression', 'model', 'function', 'point', 'curve', 'line', 'segment', 'curve', 'minima', 'minimum', 'function', 'slope', 'fact', 'consequence', 'Gradient', 'Descent', 'minimum', 'learning', 'rate', 'fact', 'cost', 'function', 'shape', 'bowl', 'bowl', 'feature', 'scale', 'figure', 'show', 'Gradient', 'Descent', 'ing', 'scale', 'left', 'training', 'set', 'feature', 'value', 'feature', 'right).5', 'Figure', 'Gradient', 'Descent', 'feature', '|', 'chapter', 'training', 'Models'], 'difficulty': 'Intermediate', 'format': 'PDF', 'duration': '13 minutes', 'learning_style': 'Reading/Writing', 'subject': 'ML', 'module': 'M3', 'file_path': '/content/ML-M3.pdf'}\n",
            "{'title': 'DS&A-M5', 'keywords': ['feast', 'language', 'scrap', 'William', 'Shakespeare', 'language', 'processing', 'NLP', 'technique', 'language', 'field', 'technique', 'Natural', 'Language', 'Processing', 'module-5', 'Word', 'Clouds', 'chapter', 'word', 'count', 'user', 'interest', 'approach', 'word', 'count', 'word', 'cloud', 'word', 'size', 'count', 'datum', 'scientist', 'word', 'cloud', 'part', 'placement', 'word', 'space', 'word', 'word', 'cloud', 'axis', 'example', 'collection', 'data', 'science', 'buzzword', 'number', 'job', 'posting', 'resume', 'data', 'datum', 'hadoop', 'Python', 'r', 'machine', 'learning', 'statistic', 'datum', 'science', 'analytic', 'team', 'player', 'synergy', 'insight', 'box', 'self', 'starter', 'customer', 'focus', 'leadership', 'word', 'cloud', 'approach', 'word', 'page', 'font', 'figure', 'Figure', 'Buzzword', 'cloud', 'approach', 'position', 'popularity', 'position', 'resume', 'popularity', 'visualization', 'insight', 'figure', 'text_size(total', 'total', 'word', 'job_popularity', 'resume_popularity', 'datum', 'plt.text(job_popularity', 'resume_popularity', 'word', \"ha='center\", 'size', '=', '+', 'resume_popularity', 'plt.xlabel(\"popularity', 'Job', 'Postings', 'plt.ylabel(\"popularity', 'Resumes', 'plt.axis([0', 'plt.xtick', 'plt.ytick', 'plt.show', 'Figure', 'word', 'cloud', 'gram', 'Models', 'DataSciencester', 'VP', 'Search', 'Engine', 'Marketing', 'thousand', 'web', 'page', 'datum', 'science', 'site', 'search', 'result', 'data', 'science', 'term', 'search', 'engine', 'algorithm', 'thousand', 'web', 'page', 'horde', 'content', 'strategist', 'web', 'page', 'way', 'modeling', 'language', 'approach', 'corpus', 'document', 'model', 'language', 'case', 'Mike', 'Loukides', 'essay', 'datum', 'science', 'chapter', 'request', 'BeautifulSoup', 'datum', 'couple', 'issue', 'attention', 'apostrophe', 'text', 'Unicode', 'character', 'u\"\\\\u2019', 'helper', 'function', 'apostrophe', 'def', 'fix_unicode(text', 'return', 'issue', 'text', 'web', 'page', 'sequence', 'word', 'period', 'sentence', 'bs4', 'import', 'BeautifulSoup', 'import', 'request', 'url', 'http://radar.oreilly.com/2010/06/what-is-data-science.html', 'html', 'requests.get(url).text', 'soup', 'content', 'soup.find(\"div', 'entry', 'content', '#', 'entry', 'regex', '#', 'word', 'period', 'document', 'paragraph', 'content(\"p', 'word', 're.findall(regex', 'fix_unicode(paragraph.text', 'document.extend(word', 'datum', 'amount', 'text', 'document', 'example', 'word', 'section', 'midsentence', 'period', 'example', 'web', 'handful', 'caption', 'list', 'document', 'text', 'sequence', 'word', 'language', 'way', 'word', 'book', 'word', 'source', 'document', 'word', 'process', 'period', 'end', 'sentence', 'bigram', 'model', 'frequency', 'bigram', 'word', 'pair', 'datum', 'word', 'word', 'period', 'word', 'transition', 'zip', 'input', 'zip(document', 'document[1', 'pair', 'element', 'document', 'bigram', '=', 'zip(document', 'document[1', 'transition', '=', 'defaultdict(list', 'prev', 'bigram', 'transitions[prev].append(current', 'sentence', 'def', 'generate_using_bigrams', '):', '=', '#', 'word', 'sentence', 'result', 'next_word_candidate', 'transitions[current', '#', '=', 'random.choice(next_word_candidate', '#', 'result.append(current', '#', 'result', '=', '#', 'sentence', 'kind', 'gibberish', 'website', 'data', 'sciencey', 'example', 'datum', 'datum', 'web', 'friend', 'topic', 'datum', 'Hadoop', 'datum', 'science', 'book', 'visualization', 'correlation', 'disk', 'drive', 'Python', 'language', 'form', 'connection', 'data', 'Bigram', 'Model', 'sentence', 'trigram', 'triplet', 'word', 'n', 'gram', 'word', 'transition', 'word', 'trigram', '=', 'zip(document', 'document[1', ':]', 'trigram_transition', 'defaultdict(list', 'prev', 'trigram', '=', '#', 'word', 'period', 'starts.append(current', '#', 'word', 'trigram_transitions[(prev', 'current)].append(next', 'word', 'sentence', 'way', 'def', 'generate_using_trigrams', 'random.choice(start', '#', 'word', 'prev', '#', '=', 'next_word_candidate', 'trigram_transitions[(prev', 'next_word', '=', 'random.choice(next_word_candidate', 'prev', '=', 'next_word', 'result.append(current', '=', 'sentence', 'hindsight', 'MapReduce', 'epidemic', 'insight', 'economy', 'question', 'year', 'Trigram', 'Model', 'step', 'generation', 'process', 'choice', 'step', 'choice', 'sentence', 'phrase', 'datum', 'datum', 'n', 'gram', 'essay', 'datum', 'science', 'grammar', 'approach', 'modeling', 'language', 'grammar', 'rule', 'sentence', 'school', 'part', 'speech', 'example', 'teacher', 'sentence', 'noun', 'verb', 'list', 'noun', 'verb', 'sentence', 'rule', 'grammar', 'grammar', '=', '_', 'S', '_', 'NP', '_', 'vp', '_', 'NP', '_', 'N', 'np', '_', 'p', '_', 'n', '_', 'VP', 'v', '_', 'v', 'NP', '_', 'N', 'datum', 'science', 'Python', 'regression', '_', 'p', '_', 'V', 'train', 'test', 'convention', 'name', 'underscore', 'refer', 'rule', 'name', 'terminal', 'processing', 'example', '_', 'S', 'sentence', 'rule', '_', 'NP', 'phrase', 'rule', '_', 'VP', 'phrase', 'rule', 'phrase', 'rule', '_', 'v', 'verb', 'rule', 'verb', 'rule', 'noun', 'phrase', 'rule', 'NP', 'rule', 'production', 'grammar', 'grammar', 'sentence', 'sentence', 'grammar', 'list', 'sentence', 'rule', 's', 'rule', 'production', 'list', 'terminal', 'example', 'progression', \"'\", 'S', '_', \"N','_VP\", \"'\", \"Python','_VP\", \"Python','trains','_NP\", \"python','trains','logistic','_np','_p','_a','_n\", \"Python','trains','logistic','_N','_P','_A','_N\", \"'\", \"python','trains','logistic','data\", \"science','_p','_a','_n\", \"Python','trains','logistic','data\", \"science','about','_a\", \"'\", 'N', \"Python','trains','logistic','data\", \"science','about','logistic','_N\", \"science','about','logistic','python\", 'helper', 'function', 'terminal', 'def', 'is_terminal(token', 'return', '=', 'function', 'list', 'token', 'sentence', 'token', 'sentence', 'production', 'production', 'terminal', 'word', 'token', 'sequence', 'space', 'token', 'token', 'way', 'process', 'set', 'token', 'expand(grammar', 'tokens', 'enumerate(token', '#', 'terminal', '#', '#', 'replacement', 'replacement', '=', 'replacement', 'tokens[:i', 'tokens[(i+1', '#', 'expand', 'list', 'token', 'expand(grammar', 'tokens', '#', 'terminal', 'return', 'token', 'sentence', 'generate_sentence(grammar', 'expand(grammar', 'grammar', 'word', 'rule', 'part', 'speech', 'web', 'page', 'company', 'grammar', 'direction', 'sentence', 'grammar', 'sentence', 'subject', 'verb', 'sense', 'sentence', 'datum', 'science', 'text', 'trick', 'text', 'Further', 'Investigation', 'library', 'Aside', 'Gibbs', 'Sampling', 'generating', 'sample', 'distribution', 'variable', 'random.random', 'variable', 'inverse_normal_cdf(random.random', 'distribution', 'gibb', 'technique', 'generating', 'sample', 'distribution', 'distribution', 'example', 'dice', 'value', 'die', 'sum', 'dice', 'lot', 'x', 'y', 'pair', 'case', 'sample', 'def', 'roll_a_die', 'return', 'random.choice([1,2,3,4,5,6', 'def', 'direct_sample', 'd1', '=', 'roll_a_die', 'd2', '=', 'roll_a_die', 'd1', 'd1', 'd2', 'distribution', 'distribution', 'y', 'value', 'x', 'y', 'x', 'x', 'x', 'x', 'def', 'random_y_given_x(x', 'x', 'x', 'return', 'x', 'roll_a_die', 'direction', 'example', 'y', 'way', 'dice', 'y', 'x', 'y', 'random_x_given_y(y', 'y', '#', 'total', 'die', 'total', 'random.randrange(1', 'y', '#', 'total', 'die', '#', 'total', 'total', 'return', 'random.randrange(y', 'way', 'Gibbs', 'work', 'value', 'x', 'y', 'value', 'y'], 'difficulty': 'Intermediate', 'format': 'PDF', 'duration': '11 minutes', 'learning_style': 'Reading/Writing', 'subject': 'DS&A', 'module': 'M5', 'file_path': '/content/DS&A-M5.pdf'}\n",
            "{'title': 'DS&A-M2', 'keywords': ['mark', 'person', 'statistic', 'George', 'Bernard', 'Shaw', 'statistic', 'probability', 'theory', 'science', 'part', 'data', 'science', 'testing', 'hypothesis', 'datum', 'process', 'Hypothesis', 'Inference', 'MODULE-2', 'Statistical', 'Hypothesis', 'Testing', 'datum', 'scientist', 'hypothesis', 'purpose', 'hypothesis', 'assertion', 'coin', 'datum', 'scientist', 'Python', 'people', 'page', 'content', 'advertisement', 'to-', 'button', 'statistic', 'datum', 'assumption', 'statistic', 'observation', 'variable', 'distribution', 'statement', 'assumption', 'setup', 'hypothesis', 'default', 'position', 'hypothesis', 'statistic', 'sense', 'example', 'example', 'Coin', 'Imagine', 'coin', 'assumption', 'coin', 'probability', 'p', 'landing', 'head', 'hypothesis', 'coin', 'hypothesis', 'test', 'coin', 'number', 'time', 'number', 'head', 'X.', 'coin', 'flip', 'Bernoulli', 'trial', 'X', 'binomial(n', 'p', 'variable', 'chapter', 'distribution', 'def', 'normal_approximation_to_binomial(n', 'p', 'mu', 'binomial(n', 'p', 'mu', 'p', '*', 'sigma', 'math.sqrt(p', 'p', 'return', 'mu', 'variable', 'distribution', 'normal_cdf', 'probability', 'value', 'interval', '#', 'cdf', '_', 'probability', 'variable', 'threshold', 'normal_probability_below', 'normal_cdf', '#', 'threshold', 'threshold', 'def', 'normal_probability_above(lo', 'mu=0', 'sigma=1', 'mu', 'sigma', '#', 'lo', 'normal_probability_between(lo', 'hi', 'mu=0', 'sigma=1', 'return', 'normal_cdf(hi', 'mu', 'sigma', 'normal_cdf(lo', 'mu', 'sigma', '#', 'normal_probability_outside(lo', 'hi', 'mu=0', 'sigma=1', 'normal_probability_between(lo', 'hi', 'mu', 'sigma', 'reverse', 'nontail', 'region', 'interval', 'mean', 'level', 'likelihood', 'example', 'interval', 'mean', '%', 'probability', 'cutoff', 'tail', '%', 'probability', '%', 'def', 'normal_upper_bound(probability', 'mu=0', 'sigma=1', 'z', 'p(z', 'z', 'probability', 'inverse_normal_cdf(probability', 'mu', 'sigma', 'normal_lower_bound(probability', 'mu=0', 'sigma=1', 'z', 'p(z', '=', 'z', 'probability', 'inverse_normal_cdf(1', 'probability', 'mu', 'sigma', 'def', 'normal_two_sided_bounds(probability', 'mu=0', 'sigma=1', 'symmetric', 'mean', 'probability', 'tail_probability', 'probability', '#', 'tail_probability', '=', 'normal_lower_bound(tail_probability', 'mu', 'sigma', '#', 'tail_probability', '=', 'normal_upper_bound(tail_probability', 'mu', 'sigma', 'return', 'coin', 'time', 'hypothesis', 'fairness', 'X', 'deviation', 'mu_0', 'sigma_0', '=', 'normal_approximation_to_binomial(1000', 'decision', 'significance', 'type', 'error', 'reason', 'annal', 'history', 'willingness', '%', '%', '%', 'test', 'x', 'bound', 'normal_two_sided_bounds(0.95', 'mu_0', 'sigma_0', '#', 'p', '%', 'chance', 'x', 'interval', 'significance', 'time', 'test', 'result', 'power', 'test', 'probability', 'type', 'error', 'order', 'mean', 'p', 'ton', 'information', 'distribution', 'X.', 'p', 'coin', 'head', 'case', 'power', 'test', '%', 'bound', 'assumption', 'p', 'lo', 'normal_two_sided_bounds(0.95', 'mu_0', 'sigma_0', '#', 'mu', 'sigma', 'p', '=', 'normal_approximation_to_binomial(1000', 'type', 'error', 'hypothesis', '#', 'X', 'interval', 'type_2_probability', 'normal_probability_between(lo', 'hi', 'sigma_1', 'power', '=', 'type_2_probability', '#', 'imagine', 'hypothesis', 'coin', 'head', 'case', 'test', 'hypothesis', 'x', 'X', 'test', 'normal_probability_below', 'cutoff', '%', 'probability', '=', 'normal_upper_bound(0.95', 'mu_0', 'sigma_0', '#', 'probability', 'tail', 'type_2_probability', 'normal_probability_below(hi', 'mu_1', 'sigma_1', 'power', '=', 'type_2_probability', '#', 'test', 'X', 'X', 'p', 'value', 'way', 'test', 'p', 'value', 'bound', 'probability', 'cutoff', 'probability', 'value', 'one', 'test', 'coin', 'def', 'two_sided_p_value(x', 'mu=0', 'sigma=1', 'mu', '#', 'mean', 'tail', 'x', 'normal_probability_above(x', 'mu', 'sigma', '#', 'mean', 'tail', 'x', 'normal_probability_below(x', 'mu', 'sigma', 'head', 'two_sided_p_value(529.5', 'mu_0', 'sigma_0', 'note', 'continuity', 'correction', 'fact', 'normal_probability_between(529.5', 'mu_0', 'sigma_0', 'estimate', 'probability', 'head', 'mu_0', 'sigma_0', 'normal_probability_above(529.5', 'mu_0', 'sigma_0', 'estimate', 'probability', 'head', 'code', 'Figure', 'way', 'estimate', 'simulation', 'extreme_value_count', 'range(100000', 'num_head', 'sum(1', 'random.random', '#', '#', 'head', '_', 'range(1000', '#', 'flip', '=', '#', 'extreme_value_count', '+', '#', '#', 'print', 'extreme_value_count', 'p', 'value', '%', 'significance', 'null', 'head', 'p', 'value', 'two_sided_p_value(531.5', 'mu_0', 'sigma_0', '#', '%', 'significance', 'null', 'test', 'way', 'statistic', 'upper_p_value', 'lower_p_value', 'normal_probability_below', 'test', 'head', 'upper_p_value(524.5', 'mu_0', 'sigma_0', '#', 'null', 'head', 'computation', 'upper_p_value(526.5', 'mu_0', 'sigma_0', '#', 'null', 'WARNING', 'datum', 'normal_probability_above', 'p', 'value', 'annal', 'datum', 'science', 'example', 'people', 'chance', 'event', 'chance', 'datum', 'data', 'test', 'normality', 'datum', 'start', 'Confidence', 'Intervals', 'hypothesis', 'value', 'head', 'probability', 'p', 'parameter', 'head', 'distribution', 'case', 'approach', 'confidence', 'interval', 'value', 'parameter', 'example', 'probability', 'coin', 'value', 'Bernoulli', 'variable', 'flip', 'head', 'tail', 'head', 'flip', 'p', 'estimate', 'value', 'p', 'limit', 'Central', 'Limit', 'Theorem', 'average', 'Bernoulli', 'variable', 'p', 'deviation', 'math.sqrt(p', 'p', 'p', 'estimate', 'mu', 'sigma', 'p_hat', 'people', 'approximation', '%', 'interval', 'parameter', 'p', 'normal_two_sided_bounds(0.95', 'mu', 'sigma', '#', 'statement', 'interval', 'p.', 'assertion', 'experiment', 'time', '%', 'time', 'parameter', 'time', 'confidence', 'interval', 'time', 'coin', 'confidence', 'interval', 'head', 'mu', 'sigma', 'p_hat', '#', 'normal_two_sided_bounds(0.95', 'mu', 'sigma', '#', 'coin', 'confidence', 'interval', 'coin', 'hypothesis', 'test', '%', 'time', 'p', 'procedure', 'hypothesis', '%', 'time', 'definition', '%', 'time', 'hypothesis', 'def', 'run_experiment', 'coin', 'time', 'head', '=', 'tail', 'random.random', '_', 'range(1000', 'reject_fairness(experiment', '%', 'significance', 'level', 'num_heads', '=', 'flip', 'experiment', 'random.seed(0', 'experiment', '_', 'range(1000', 'num_rejection', 'experiment', 'experiment', 'reject_fairness(experiment', 'print', 'num_rejection', 'result', 'hypothesis', 'datum', 'set', 'outlier', 'p', 'value', 'Correlation', 'p', 'hacking', 'way', 'consequence', 'inference', 'p', 'value', 'framework', 'article', 'approach', 'Earth', 'Round', 'science', 'hypothesis', 'datum', 'datum', 'hypothesis', 'mind', 'mind', 'p', 'value', 'substitute', 'sense', 'approach', 'Bayesian', 'Inference', 'example', 'A', 'B', 'Test', 'responsibility', 'DataSciencester', 'experience', 'optimization', 'euphemism', 'people', 'advertisement', 'advertiser', 'energy', 'drink', 'datum', 'scientist', 'VP', 'Advertisements', 'help', 'advertisement', 'advertisement', 'b', 'bias', 'scientist', 'experiment', 'site', 'visitor', 'advertisement', 'people', 'one', 'A', 'viewer', 'ad', 'b', 'viewer', 'ad', 'a', 'ad', 'difference', 'inference', 'people', 'ad', 'a', 'ad', 'view', 'Bernoulli', 'trial', 'probability', 'ad', 'a.', 'variable', 'deviation', 'variable', 'mean', 'deviation', 'def', 'estimated_parameters(N', '):', 'p', 'N', 'sigma', 'math.sqrt(p', 'p', 'N', 'return', 'p', 'normal', 'Bernoulli', 'trial', 'difference', 'deviation', 'note', 'math', 'deviation', 'datum', 't', 'distribution', 'datum', 'set', 'difference', 'hypothesis', 'statistic', 'def', 'a_b_test_statistic(N_A', 'n_a', 'p_a', 'sigma_A', '=', 'estimated_parameters(n_a', 'n_a', 'p_B', 'sigma_B', 'return', 'p_b', 'p_a', 'example', 'click', 'view', 'bias', 'click', 'view', 'statistic', 'z', 'a_b_test_statistic(1000', '#', 'probability', 'difference', 'mean', 'difference', 'hand', 'bias', 'click', 'z', 'a_b_test_statistic(1000', '#', 'two_sided_p_value(z', '#', 'probability', 'difference', 'ad'], 'difficulty': 'Intermediate', 'format': 'PDF', 'duration': '12 minutes', 'learning_style': 'Reading/Writing', 'subject': 'DS&A', 'module': 'M2', 'file_path': '/content/DS&A-M2.pdf'}\n",
            "{'title': 'DS&A-M3', 'keywords': ['Winston', 'Churchill', 'people', 'datum', 'science', 'machine', 'learning', 'datum', 'scientist', 'train', 'machine', 'model', 'day', 'people', 'machine', 'learning', 'fact', 'datum', 'science', 'business', 'problem', 'data', 'problem', 'datum', 'datum', 'cleaning', 'datum', 'formatting', 'datum', 'machine', 'learning', 'afterthought', 'afterthought', 'order', 'data', 'science', 'Machine', 'Learning', 'MODULE-3', 'Modeling', 'machine', 'model', 'model', 'specification', 'relationship', 'variable', 'instance', 'money', 'networking', 'site', 'business', 'model', 'spreadsheet', 'input', 'number', 'user', 'ad', 'revenue', 'user', 'number', 'employee', 'profit', 'year', 'cookbook', 'recipe', 'model', 'input', 'number', 'eater', 'hungriness', 'quantity', 'ingredient', 'poker', 'television', 'player', 'probability', 'time', 'model', 'account', 'card', 'distribution', 'card', 'deck', 'business', 'model', 'relationship', 'profit', 'revenue', 'expense', 'revenue', 'unit', 'time', 'price', 'recipe', 'model', 'trial', 'error', 'kitchen', 'combination', 'ingredient', 'poker', 'model', 'probability', 'theory', 'rule', 'poker', 'assumption', 'process', 'card', 'Machine', 'Learning', 'definition', 'machine', 'learning', 'model', 'datum', 'context', 'modeling', 'data', 'mining', 'machine', 'learning', 'goal', 'datum', 'model', 'outcome', 'datum', 'email', 'message', 'spam', 'credit', 'card', 'transaction', 'predicting', 'advertisement', 'shopper', 'predicting', 'football', 'team', 'Super', 'Bowl', 'model', 'set', 'datum', 'answer', 'model', 'label', 'type', 'datum', 'model', 'datum', 'book', 'situation', 'universe', 'model', 'relationship', 'case', 'family', 'model', 'datum', 'parameter', 'way', 'instance', 'person', 'height', 'function', 'weight', 'datum', 'function', 'decision', 'tree', 'way', 'disease', 'patient', 'datum', 'tree', 'rest', 'book', 'family', 'model', 'fundamental', 'machine', 'learning', 'rest', 'chapter', 'concept', 'model', 'Overfitting', 'Underfitting', 'danger', 'machine', 'learning', 'model', 'datum', 'datum', 'noise', 'datum', 'input', 'factor', 'output', 'side', 'model', 'training', 'datum', 'model', 'figure', 'overfitting', 'underfitting', 'figure', 'polynomial', 'sample', 'datum', 'chapter', 'line', 'degree', 'polynomial', 'training', 'datum', 'fit', 'degree', 'parameter', 'training', 'datum', 'overfit', 'datum', 'point', 'lot', 'degree', 'line', 'balance', 'point', 'datum', 'line', 'datum', 'point', 'model', 'lead', 'overfitting', 'datum', 'model', 'approach', 'datum', 'model', 'model', 'way', 'datum', 'example', 'third', 'model', 'model', 'performance', 'third', 'split_data(data', 'prob', 'split', 'datum', 'fraction', 'prob', 'row', 'datum', 'results[0', 'random.random', 'prob', '1].append(row', 'return', 'result', 'matrix', 'x', 'input', 'variable', 'vector', 'y', 'output', 'variable', 'case', 'value', 'training', 'datum', 'test', 'datum', 'def', 'y', 'test_pct', 'datum', '=', 'zip(x', 'y', '#', 'value', 'train', 'test', '=', 'split_data(data', 'test_pct', '#', 'datum', 'pair', 'zip(*train', '#', '-', 'zip', 'trick', '=', 'zip(*test', 'return', 'y_train', 'model', '=', 'SomeKindOfModel', 'train_test_split(xs', 'ys', 'model.train(x_train', 'performance', 'model.test(x_test', 'model', 'training', 'datum', 'test', 'datum', 'test', 'datum', 'couple', 'way', 'pattern', 'test', 'train', 'datum', 'datum', 'set', 'example', 'datum', 'consist', 'user', 'activity', 'row', 'user', 'week', 'case', 'user', 'training', 'datum', 'test', 'datum', 'model', 'user', 'relationship', 'attribute', 'worry', 'problem', 'test', 'train', 'split', 'model', 'model', 'case', 'model', 'model', 'test', 'set', 'meta', 'training', 'test', 'function', 'training', 'set', 'model', 'test', 'set', 'test', 'set', 'situation', 'datum', 'part', 'training', 'building', 'model', 'validation', 'model', 'test', 'model', 'Correctness', 'data', 'science', 'medicine', 'time', 'test', 'baby', '%', 'accuracy', 'newborn', 'leukemia', 'lawyer', 'test', 'detail', 'leukemia', 'baby', 'Luke', 'leukemia', 'test', '%', 'test', 'illustration', 'accuracy', 'model', 'model', 'judgment', 'email', 'spam', 'candidate', 'air', 'traveler', 'terrorist', 'set', 'datum', 'model', 'datum', 'point', 'category', 'message', 'spam', 'spam', 'type', 'Error', 'message', 'spam', 'type', 'error', 'message', 'spam', 'spam', 'negative', 'message', 'spam', 'count', 'confusion', 'matrix', 'Spam', 'Spam', 'Spam', 'True', 'Positive', 'False', 'Positive', 'Spam', 'False', 'Negative', 'True', 'Negative', 'leukemia', 'test', 'framework', 'day', 'baby', 'Luke', 'lifetime', 'prevalence', 'leukemia', '%', 'people', 'factor', 'Luke', 'leukemia', 'test', 'people', 'confusion', 'matrix', 'leukemia', 'total', 'Luke', 'Luke', 'statistic', 'model', 'performance', 'example', 'accuracy', 'fraction', 'prediction', 'def', 'accuracy(tp', 'fp', 'fn', 'tn', '=', 'tp', 'tn', '=', 'tp', 'fp', '+', 'fn', '+', 'tn', 'print', 'accuracy(70', '#', 'number', 'test', 'lot', 'credence', 'accuracy', 'combination', 'precision', 'recall', 'precision', 'measure', 'prediction', 'precision(tp', 'fp', 'fn', 'tn', 'return', 'tp', 'tp', 'fp', 'print', 'precision(70', 'measure', 'fraction', 'positive', 'model', 'def', 'recall(tp', 'fp', 'fn', 'tn', 'return', 'tp', 'tp', 'fn', 'print', 'recall(70', 'number', 'model', 'precision', 'recall', 'F1', 'score', 'def', 'f1_score(tp', 'fp', 'fn', 'tn', 'p', 'precision(tp', 'fp', 'fn', 'tn', 'r', 'recall(tp', 'fp', 'fn', 'tn', '*', 'p', 'r', 'p', 'r', 'mean', 'precision', 'recall', 'choice', 'model', 'trade', 'off', 'precision', 'recall', 'model', 'bit', 'recall', 'precision', 'model', 'recall', 'precision', 'trade', 'off', 'positive', 'negative', 'lot', 'positive', 'lot', 'negative', 'risk', 'factor', 'leukemia', 'leukemia', 'case', 'continuum', 'test', 'leukemia', 'risk', 'factor', 'leukemia', 'risk', 'factor', 'threshhold', 'test', 'precision', 'people', 'risk', 'factor', 'disease', 'test', 'recall', 'disease', 'sufferer', 'threshhold', 'case', 'threshhold', 'matter', 'trade', 'off', 'Bias', 'Variance', 'Trade', 'way', 'problem', 'trade', 'off', 'bias', 'variance', 'measure', 'model', 'time', 'set', 'training', 'datum', 'population', 'example', 'degree', 'model', 'Overfitting', 'Underfitting', 'lot', 'mistake', 'training', 'population', 'bias', 'training', 'set', 'model', 'training', 'set', 'value', 'variance', 'bias', 'variance', 'underfitting', 'hand', 'degree', 'model', 'training', 'bias', 'variance', 'training', 'set', 'rise', 'model', 'model', 'problem', 'way', 'model', 'model', 'bias', 'training', 'datum', 'thing', 'feature', 'degree', 'model', 'Overfitting', 'Underfitting', 'degree', 'model', 'improvement', 'model', 'variance', 'feature', 'solution', 'datum'], 'difficulty': 'Intermediate', 'format': 'PDF', 'duration': '11 minutes', 'learning_style': 'Reading/Writing', 'subject': 'DS&A', 'module': 'M3', 'file_path': '/content/DS&A-M3.pdf'}\n",
            "{'title': 'SE-M1', 'keywords': ['software', 'system', 'IMPORTANCE', 'SOFTWARE', 'ENGINEERING', 'Software', 'Engineering', 'discipline', 'designing', 'writing', 'testing', 'form', 'basis', 'design', 'development', 'computer', 'system', 'Software', 'Engineering', 'fault', 'software', 'time', 'budget', 'requirement', 'need', 'client', 'PRIMARY', 'GOALS', 'SOFTWARE', 'engineering', 'quality', 'software', 'product', 'productivity', 'job', 'satisfaction', 'software', 'engineer', 'SOFTWARE', 'ENGINEERING', 'need', 'software', 'engineering', 'rate', 'change', 'user', 'requirement', 'environment', 'software', 'factor', 'need', 'software', 'engineering', 'Software', 'scalability', 'cost', 'nature', 'Quality', 'Management', 'nature', 'SOFTWARE', 'Software', 'role', 'product', 'vehicle', 'product', 'product', 'computing', 'potential', 'computer', 'Hardware', 'network', 'computer', 'vehicle', 'information', 'transformer', 'information', 'bit', 'multimedia', 'presentation', 'Software', 'product', 'time', 'information', 'datum', 'business', 'information', 'competitiveness', 'gateway', 'information', 'network', 'Computer', 'Software', 'engineer', 'computer', 'science', 'engineering', 'math', 'Software', 'Engineers', 'analyse', 'user', 'need', 'test', 'design', 'test', 'software', 'Software', 'Software', 'Engineering', 'mean', 'information', 'Improvements', 'hardware', 'performance', 'increase', 'memory', 'storage', 'capacity', 'variety', 'input', 'output', 'option', 'SOFTWARE', 'Software', 'program', 'code', 'program', 'code', 'purpose', 'software', 'collection', 'programming', 'code', 'library', 'documentation', 'Software', 'requirement', 'software', 'product', 'Computer', 'program', 'documentation', 'software', 'product', 'customer', 'market', 'product', 'software', 'professional', 'term', 'Software', 'instruction', 'computer', 'program', 'feature', 'function', 'performance', 'Data', 'structure', 'program', 'information', 'documentation', 'operation', 'use', 'program', 'CHARACTERISTICS', 'SOFTWARE', 'software', 'sense', 'software', 'industry', 'component', 'construction', 'software', 'custom', 'nature', 'SOFTWARE', 'category', 'computer', 'software', 'challenge', 'software', 'engineer', 'system', 'software', 'application', 'software', 'engineering', 'software', 'software', 'product', 'line', 'software', 'web', 'application', 'intelligence', 'software', 'system', 'software', 'system', 'software', 'collection', 'program', 'program', 'system', 'software', 'interaction', 'computer', 'hardware', 'usage', 'user', 'operation', 'scheduling', 'resource', 'sharing', 'process', 'management', 'datum', 'structure', 'interface', 'E.g.', 'compiler', 'editor', 'file', 'management', 'utility', 'application', 'software', 'application', 'software', 'program', 'business', 'need', 'business', 'operation', 'management', 'decision', 'making', 'business', 'function', 'time', 'E.g.', 'point', 'sale', 'transaction', 'processing', 'time', 'manufacturing', 'process', 'control', 'Engineering', 'software', 'engineering', 'application', 'range', 'astronomy', 'volcanology', 'stress', 'analysis', 'space', 'shuttle', 'dynamic', 'biology', 'manufacturing', 'computer', 'design', 'system', 'simulation', 'application', 'software', 'software', 'product', 'system', 'feature', 'function', 'end', 'user', 'system', 'function', 'function', 'control', 'capability', 'product', 'line', 'software', 'capability', 'use', 'customer', 'product', 'line', 'software', 'marketplace', 'mass', 'consumer', 'market', 'word', 'processing', 'sheet', 'computer', 'graphic', 'multimedia', 'entertainment', 'database', 'management', 'business', 'application', 'web', 'application', 'WebApps', 'network', 'software', 'category', 'array', 'application', 'form', 'WebApps', 'set', 'file', 'information', 'text', 'graphic', 'intelligence', 'software', 'use', 'algorithm', 'problem', 'computation', 'analysis', 'application', 'area', 'robotic', 'expert', 'system', 'pattern', 'recognition', 'image', 'voice', 'network', 'proving', 'game', 'playing', 'LEGACY', 'software', 'hundred', 'thousand', 'computer', 'program', 'application', 'domain', 'art', 'software', 'individual', 'industry', 'government', 'program', 'case', 'program', 'legacy', 'software', 'focus', 'attention', 'concern', '1960', 'Dayani', 'Fard', 'colleague', 'legacy', 'software', 'way', 'Legacy', 'software', 'system', 'decade', 'change', 'business', 'requirement', 'platform', 'proliferation', 'system', 'headache', 'organization', 'Liu', 'colleague', 'description', 'legacy', 'system', 'business', 'function', 'business', 'legacy', 'software', 'longevity', 'business', 'criticality', 'Legacy', 'system', 'reason', 'software', 'need', 'computing', 'environment', 'technology', '•', 'software', 'business', 'requirement', '•', 'software', 'system', 'database', '•', 'software', 'network', 'environment', 'UNIQUE', 'nature', 'WEBAPPS', 'day', 'World', 'Wide', 'Web', 'website', 'set', 'file', 'information', 'text', 'graphic', 'time', 'augmentation', 'html', 'development', 'tool', 'XML', 'Java', 'web', 'engineer', 'computing', 'capability', 'content', 'web', 'system', 'application', 'today', 'WebApps', 'computing', 'tool', 'function', 'end', 'user', 'database', 'business', 'application', 'attribute', 'majority', 'WebApps', 'Network', 'intensiveness', 'webapp', 'network', 'need', 'community', 'client', 'network', 'access', 'communication', 'internet', 'access', 'communication', 'Intranet', 'concurrency', 'number', 'user', 'webapp', 'time', 'case', 'pattern', 'usage', 'end', 'user', 'load', 'number', 'user', 'WebApp', 'order', 'magnitude', 'day', 'day', 'example', 'user', 'Monday', 'system', 'Thursday', 'performance', 'webapp', 'user', 'access', 'serverside', 'processing', 'client', 'side', 'formatting', 'display', 'availability', 'expectation', 'percent', 'availability', 'user', 'WebApps', 'access', 'basis', 'Data', 'function', 'WebApps', 'hypermedia', 'text', 'graphic', 'audio', 'video', 'content', 'end', 'user', 'addition', 'WebApps', 'information', 'database', 'part', 'web', 'environment', 'e', '-', 'commerce', 'application', 'Content', 'quality', 'nature', 'content', 'determinant', 'quality', 'WebApp', 'Continuous', 'evolution', 'application', 'software', 'series', 'release', 'web', 'application', 'WebApps', 'content', 'by-', 'minute', 'schedule', 'content', 'request', 'security', 'WebApps', 'network', 'access', 'population', 'end', 'user', 'application', 'order', 'content', 'mode', 'datum', 'transmission', 'security', 'measure', 'infrastructure', 'WebApp', 'application', 'aesthetic', 'part', 'appeal', 'WebApp', 'look', 'application', 'product', 'idea', 'aesthetic', 'success', 'design', 'SOFTWARE', 'ENGINEERING', 'order', 'software', 'challenge', 'reality', 'effort', 'problem', 'software', 'solution', 'design', 'software', 'engineering', 'activity', 'quality', 'maintainability', 'outgrowth', 'design', 'reality', 'conclusion', 'software', 'form', 'application', 'domain', 'product', 'principle', 'method', 'software', 'engineering', 'engineering', 'branch', 'development', 'software', 'product', 'principle', 'method', 'procedure', 'outcome', 'software', 'engineering', 'software', 'product', 'Software', 'analyze', 'user', 'need', 'test', 'software', 'system', 'IEEE', 'software', 'engineering', 'application', 'approach', 'development', 'operation', 'maintenance', 'software', 'SOFTWARE', 'ENGINEERING', 'A', 'LAYERED', 'TECHNOLOGY', 'Software', 'engineering', 'technology', 'engineering', 'approach', 'commitment', 'quality', 'bedrock', 'software', 'engineering', 'quality', 'focus', 'foundation', 'software', 'engineering', 'process', 'layer', 'software', 'engineering', 'process', 'glue', 'technology', 'layer', 'process', 'framework', 'delivery', 'software', 'engineering', 'technology', 'software', 'basis', 'management', 'control', 'software', 'project', 'context', 'method', 'work', 'product', 'milestone', 'quality', 'change', 'SOFTWARE', 'process', 'process', 'collection', 'activity', 'action', 'task', 'work', 'product', 'activity', 'objective', 'communication', 'stakeholder', 'application', 'domain', 'size', 'project', 'complexity', 'effort', 'degree', 'rigor', 'software', 'engineering', 'action', 'design', 'set', 'task', 'work', 'product', 'design', 'model', 'task', 'objective', 'unit', 'test', 'outcome', 'context', 'software', 'engineering', 'process', 'prescription', 'computer', 'software', 'approach', 'people', 'work', 'software', 'team', 'set', 'work', 'action', 'task', 'intent', 'software', 'manner', 'quality', 'creation', 'process', 'framework', 'foundation', 'software', 'engineering', 'process', 'number', 'framework', 'activity', 'software', 'project', 'size', 'complexity', 'addition', 'process', 'framework', 'set', 'umbrella', 'activity', 'software', 'process', 'process', 'framework', 'software', 'engineering', 'activity', 'communication', 'work', 'customer', 'intent', 'stakeholder', 'objective', 'project', 'requirement', 'software', 'feature', 'function', 'planning', 'journey', 'map', 'software', 'project', 'journey', 'planning', 'activity', 'map', 'team', 'journey', 'map', 'software', 'project', 'plan', 'software', 'engineering', 'work', 'task', 'risk', 'resource', 'work', 'product', 'work', 'schedule', 'modelling', 'landscaper', 'bridge', 'builder', 'engineer', 'carpenter', 'architect', 'model', 'day', 'sketch', 'thing', 'picture', 'constituent', 'part', 'characteristic', 'sketch', 'detail', 'effort', 'problem', 'software', 'engineer', 'thing', 'model', 'software', 'requirement', 'design', 'requirement', 'construction', 'activity', 'code', 'generation', 'testing', 'error', 'code', 'Deployment', 'software', 'entity', 'increment', 'customer', 'product', 'feedback', 'evaluation', 'framework', 'activity', 'development', 'program', 'creation', 'web', 'application', 'engineering', 'computer', 'system', 'detail', 'software', 'process', 'case', 'framework', 'activity', 'software', 'project', 'framework', 'activity', 'project', 'progress', 'communication', 'planning', 'modelling', 'construction', 'deployment', 'number', 'project', 'iteration', 'project', 'iteration', 'software', 'increment', 'stakeholder', 'subset', 'software', 'feature', 'functionality', 'increment', 'software', 'Software', 'engineering', 'process', 'framework', 'activity', 'number', 'umbrella', 'activity', 'umbrella', 'activity', 'software', 'project', 'software', 'team', 'control', 'progress', 'quality', 'change', 'risk', 'umbrella', 'activity', 'Software', 'project', 'tracking', 'control', 'software', 'team', 'progress', 'project', 'plan', 'action', 'schedule', 'risk', 'management', 'risk', 'outcome', 'project', 'quality', 'product', 'software', 'quality', 'assurance', 'define', 'activity', 'software', 'quality', 'review', 'software', 'engineering', 'work', 'product', 'effort', 'error', 'activity', 'Measurement', 'define', 'collect', 'process', 'project', 'product', 'measure', 'team', 'software', 'stakeholder', 'need', 'conjunction', 'framework', 'umbrella', 'activity', 'Software', 'configuration', 'management', 'effect', 'change', 'software', 'process', 'Reusability', 'management', 'define', 'criterion', 'work', 'product', 'reuse', 'software', 'component', 'mechanism', 'component', 'work', 'product', 'preparation', 'production', 'activity', 'work', 'product', 'model', 'document', 'log', 'form', 'SOFTWARE', 'engineering', 'PRACTICE', 'essence', 'practice', 'essence', 'software', 'engineering', 'practice', 'problem', 'communication', 'analysis', 'solution', 'modeling', 'software', 'design', 'plan', 'code', 'generation', 'result', 'accuracy', 'testing', 'quality', 'assurance', 'context', 'software', 'engineering', 'sense', 'step', 'series', 'question', 'problem', 'hubris', 'problem', 'second', 'thing', 'understanding', 'time', 'question', '•', 'stake', 'solution', 'problem', 'stakeholder', 'unknown', 'data', 'function', 'feature', 'problem', 'problem', 'problem', 'problem', 'analysis', 'model', 'solution', 'problem', 'bit', 'design', 'problem', 'pattern', 'solution', 'software', 'datum', 'function', 'problem', 'element', 'solution', '•', 'subproblem', 'solution', 'subproblem', 'solution', 'manner', 'implementation', 'design', 'model', 'plan', 'design', 'serve', 'road', 'map', 'system', 'detour', 'route', 'plan', 'solution', 'plan', 'source', 'code', 'design', 'model', 'component', 'part', 'solution', 'design', 'code', 'correctness', 'proof', 'algorithm', 'result', 'solution', 'number', 'test', 'error', 'component', 'part', 'solution', 'testing', 'strategy', 'solution', 'result', 'datum', 'function', 'feature', 'software', 'stakeholder', 'requirement', 'GENERAL', 'PRINCIPLE', 'word', 'principle', 'law', 'assumption', 'system', 'thought', 'focus', 'software', 'engineering', 'whole', 'other', 'framework', 'activity', 'communication', 'other', 'software', 'engineering', 'action', 'design', 'task', 'usage', 'scenario', 'level', 'focus', 'principle', 'mind', 'software', 'engineering', 'practice', 'David', 'Hooker', 'Hoo96', 'principle', 'software', 'engineering', 'practice', 'whole', 'paragraph', 'First', 'Principle', 'Reason', 'software', 'system', 'reason', 'value', 'user', 'decision', 'mind', 'system', 'requirement', 'piece', 'system', 'functionality', 'hardware', 'platform', 'development', 'process', 'question', 'value', 'system', 'answer', 'principle', 'one', 'Second', 'Principle', 'KISS', 'Simple', 'Stupid', 'Software', 'design', 'haphazard', 'process', 'factor', 'design', 'effort', 'design', 'facilitate', 'system', 'feature', 'feature', 'name', 'simplicity', 'design', 'one', 'Simple', 'fact', 'lot', 'thought', 'iteration', 'payoff', 'software', 'error', 'Third', 'Principle', 'Vision', 'vision', 'success', 'software', 'project', 'project', 'mind', 'integrity', 'system', 'patchwork', 'design', 'kind', 'screw', 'vision', 'software', 'system', 'system', 'architect', 'vision', 'compliance', 'software', 'project', 'Fourth', 'Principle', 'other', 'Consume', 'Seldom', 'strength', 'software', 'system', 'vacuum', 'way', 'document', 'system', 'design', 'audience', 'product', 'software', 'development', 'eye', 'user', 'design', 'implementer', 'mind', 'Code', 'concern', 'system', 'code', 'user', 'code', 'job', 'value', 'system', 'Fifth', 'Principle', 'Future', 'system', 'lifetime', 'value', 'today', 'computing', 'environment', 'specification', 'moment', 'notice', 'hardware', 'platform', 'month', 'software', 'lifetime', 'month', 'year', 'strength', 'software', 'system', 'system', 'change', 'system', 'way', 'start', 'corner', 'answer', 'system', 'problem', 'one.14', 'reuse', 'system', 'Sixth', 'principle', 'Reuse', 'Reuse', 'time', 'level', 'reuse', 'goal', 'software', 'system', 'reuse', 'code', 'design', 'benefit', 'object', 'technology', 'return', 'investment', 'reuse', 'possibility', 'object', 'programming', 'forethought', 'planning', 'technique', 'reuse', 'level', 'system', 'development', 'process', 'reuse', 'cost', 'value', 'component', 'system', 'principle', 'principle', 'thought', 'action', 'result', 'knowledge', 'experience', 'side', 'effect', 'thinking', 'point', 'answer', 'thought', 'system', 'value', 'principle', 'thought', 'reward'], 'difficulty': 'Hard', 'format': 'PDF', 'duration': '19 minutes', 'learning_style': 'Reading/Writing', 'subject': 'SE', 'module': 'M1', 'file_path': '/content/SE-M1.pdf'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "create_database(db_name)\n",
        "insert_metadata(db_name, metadata_list)\n",
        "query_and_display_pdfs(db_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAJYEEgT2Yfm",
        "outputId": "440a8ea1-79cb-4fda-8875-22afbf85f835"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID    | Title                          | Keywords                       | Difficulty      | Format     | Duration   | Learning Style       | Subject              | Module               | File Path                                         \n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "1     | ML-M2                          | dataset,R.,Kelley,Pace,Ronald,... | Intermediate    | PDF        | 15 minutes | Reading/Writing      | ML                   | M2                   | /content/ML-M2.pdf                                \n",
            "2     | ML-M5                          | chapter,BAYESIAN,LEARNING,reas... | Hard            | PDF        | 19 minutes | Reading/Writing      | ML                   | M5                   | /content/ML-M5.pdf                                \n",
            "3     | DS&A-M4                        | tree,mystery,Jim,Woodring,Data... | Intermediate    | PDF        | 10 minutes | Reading/Writing      | DS&A                 | M4                   | /content/DS&A-M4.pdf                              \n",
            "4     | ML-M4                          | decision,tree,Early,Release,eb... | Intermediate    | PDF        | 13 minutes | Reading/Writing      | ML                   | M4                   | /content/ML-M4.pdf                                \n",
            "5     | DS&A-M1                        | joke,data,scientist,statistic,... | Intermediate    | PDF        | 12 minutes | Reading/Writing      | DS&A                 | M1                   | /content/DS&A-M1.pdf                              \n",
            "6     | ML-M1                          | Machine,Learning,Machine,Learn... | Intermediate    | PDF        | 10 minutes | Reading/Writing      | ML                   | M1                   | /content/ML-M1.pdf                                \n",
            "7     | ML-M3                          | training,Models,Early,Release,... | Intermediate    | PDF        | 13 minutes | Reading/Writing      | ML                   | M3                   | /content/ML-M3.pdf                                \n",
            "8     | DS&A-M5                        | feast,language,scrap,William,S... | Intermediate    | PDF        | 11 minutes | Reading/Writing      | DS&A                 | M5                   | /content/DS&A-M5.pdf                              \n",
            "9     | DS&A-M2                        | mark,person,statistic,George,B... | Intermediate    | PDF        | 12 minutes | Reading/Writing      | DS&A                 | M2                   | /content/DS&A-M2.pdf                              \n",
            "10    | DS&A-M3                        | Winston,Churchill,people,datum... | Intermediate    | PDF        | 11 minutes | Reading/Writing      | DS&A                 | M3                   | /content/DS&A-M3.pdf                              \n",
            "11    | SE-M1                          | software,system,IMPORTANCE,SOF... | Hard            | PDF        | 19 minutes | Reading/Writing      | SE                   | M1                   | /content/SE-M1.pdf                                \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#testing if the query is properly retriving the data or not\n",
        "# Function to query and retrieve metadata for a specific PDF\n",
        "def query_pdf_metadata(db_name, pdf_title):\n",
        "    conn = sqlite3.connect(db_name)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # Execute the query to retrieve metadata for the given PDF title\n",
        "    cursor.execute('''\n",
        "        SELECT * FROM pdfs WHERE title = ?\n",
        "    ''', (pdf_title,))\n",
        "    row = cursor.fetchone()\n",
        "\n",
        "    # Close connection\n",
        "    conn.close()\n",
        "\n",
        "    return row\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    db_name = 'pdfnotes_metadata.db'\n",
        "    pdf_title = \"DS&A-M4\"\n",
        "\n",
        "    # Query metadata for the specific PDF title\n",
        "    pdf_metadata = query_pdf_metadata(db_name, pdf_title)\n",
        "\n",
        "    # Display metadata\n",
        "    if pdf_metadata:\n",
        "        pdf_id, title, keywords, difficulty, format, duration, learning_style, subject, module, file_path = pdf_metadata\n",
        "        print(f\"Title: {title}\")\n",
        "        print(f\"Keywords: {keywords}\")\n",
        "        print(f\"Difficulty: {difficulty}\")\n",
        "        print(f\"Format: {format}\")\n",
        "        print(f\"Duration: {duration}\")\n",
        "        print(f\"Learning Style: {learning_style}\")\n",
        "        print(f\"Subject: {subject}\")\n",
        "        print(f\"Module: {module}\")\n",
        "        print(f\"File Path: {file_path}\")\n",
        "    else:\n",
        "        print(f\"PDF '{pdf_title}' not found in the database.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPI0B7Xe9fqp",
        "outputId": "8dbe9b26-5c89-48cd-d80b-c500f6250bb8"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: DS&A-M4\n",
            "Keywords: tree,mystery,Jim,Woodring,DataSciencester,VP,Talent,number,job,candidate,site,degree,success,data,attribute,candidate,candidate,datum,model,identifying,candidate,time,interview,fit,decision,tree,modeling,tool,data,scientist,kit,Decision,Trees,MODULE-4,decision,tree,decision,tree,tree,structure,number,decision,path,outcome,path,game,Twenty,Questions,decision,tree,example,animal,leg,no,no,back,cent,coin,echidna,path,leg,cent,coin,Echidna,idiosyncratic,animal,decision,tree,figure,figure,animal,decision,tree,decision,tree,lot,process,prediction,model,decision,tree,mix,number,leg,delicious,attribute,datum,attribute,time,decision,tree,set,training,datum,problem,tree,one,data,set,lot,work,decision,tree,training,datum,datum,way,people,decision,tree,classification,tree,output,regression,tree,output,chapter,classification,tree,ID3,algorithm,decision,tree,set,datum,decision,tree,thing,problem,output,candidate,website,visitor,advertisement,a,advertisement,b,food,office,fridge,Entropy,order,decision,tree,question,order,stage,tree,possibility,animal,leg,possibility,grasshopper,possibility,duck,question,possibility,answer,question,answer,lot,information,tree,question,answer,output,answer,output,vice,question,question,answer,information,prediction,choice,notion,information,entropy,disorder,uncertainty,datum,S,datum,member,number,class,datum,point,class,uncertainty,entropy,data,point,class,lot,uncertainty,entropy,math,term,proportion,datum,class,entropy,standard,convention,detail,term,figure,figure,graph,entropy,datum,class,’s,datum,class,behavior,function,entropy(class_probabilitie,list,class,probability,entropy,sum(-p,p,class_probabilitie,p,#,probability,datum,pair,input,label,class,label,probability,probability,class_probabilities(labels,=,len(label,return,count,counter(labels).value,def,data_entropy(labeled_data,label,_,label,labeled_data,probability,class_probabilities(labels,entropy(probabilitie,Entropy,Partition,entropy,uncertainty,set,datum,stage,decision,tree,question,answer,partition,datum,subset,instance,leg,question,partition,animal,leg,spider,echidna,notion,entropy,set,datum,way,partition,entropy,datum,subset,entropy,entropy,subset,entropy,example,cent,coin,question,animal,point,=,echidna,=,entropy,entropy,fraction,class,datum,S,subset,proportion,datum,entropy,partition,sum,partition_entropy(subsets,entropy,partition,datum,subset,subset,list,list,datum,=,sum(len(subset,subset,subset,return,sum,data_entropy(subset,len(subset,subset,subset,note,problem,approach,attribute,value,entropy,overfitting,example,bank,decision,tree,customer,mortgage,datum,training,set,datum,customer,Social,Security,number,SSN,person,subset,entropy,model,SSN,training,set,reason,attribute,number,value,decision,tree,decision,tree,VP,datum,specification,input,label,input,dict,candidate,attribute,label,candidate,False,candidate,candidate,level,language,Twitter,phd,level':'senior,lang':'java,',False,level':'senior,lang':'java,',phd':'yes,',False,',level':'Mid,lang':'python,',',lang':'python,',',',phd':'yes,',False,',level':'Mid,phd':'yes,',level':'senior,lang':'python,',False,level':'senior,',lang':'python,level':'senior,lang':'python,phd':'yes,',',level':'Mid,lang':'python,',phd':'yes,',',level':'Mid,lang':'java,',lang':'python,',phd':'yes,',tree,decision,node,question,answer,leaf,node,prediction,ID3,algorithm,manner,datum,list,attribute,datum,label,leaf,node,label,list,attribute,question,leaf,node,label,datum,attribute,partition,partition,entropy,decision,node,attribute,Recur,subset,attribute,algorithm,step,option,data,set,tree,move,algorithm,place,decision,tree,step,data,set,datum,set,label,attribute,step,partition,entropy,function,partitioning,partition_by(input,attribute,input,pair,attribute_dict,label,dict,>,input,group,defaultdict(list,input,input,=,input[0][attribute,#,value,attribute,groups[key].append(input,#,input,list,return,group,entropy,def,partition_entropy_by(input,attribute,entropy,partition,partition,=,partition_by(inputs,attribute,return,partition_entropy(partitions.value,entropy,partition,datum,key,level','lang','tweets','phd,print,key,partition_entropy_by(input,#,level,#,lang,#,#,phd,entropy,level,subtree,level,value,candidate,Mid,subtree,leaf,node,True,candidate,mix,Trues,Falses,input,label,input,label,input,input[\"level,key,',lang,',tweet,',phd,print,key,partition_entropy_by(senior_input,#,lang,#,#,phd,split,tweet,entropy,partition,level,candidate,tweet,tweet,False,thing,Junior,candidate,splitting,phd,phd,phd,False,figure,decision,tree,figure,decision,tree\n",
            "Difficulty: Intermediate\n",
            "Format: PDF\n",
            "Duration: 10 minutes\n",
            "Learning Style: Reading/Writing\n",
            "Subject: DS&A\n",
            "Module: M4\n",
            "File Path: /content/DS&A-M4.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the content of the database created\n",
        "# Connect to SQLite database\n",
        "conn = sqlite3.connect('pdfnotes_metadata.db')\n",
        "\n",
        "# Query the database to fetch metadata\n",
        "query = \"SELECT * FROM pdfs\"\n",
        "df = pd.read_sql_query(query, conn)\n",
        "\n",
        "# Close the database connection\n",
        "conn.close()\n",
        "\n",
        "# Display the loaded dataset\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KngFDYOE-LO9",
        "outputId": "c89006ce-e03c-4813-9d63-fdeae54950ac"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id    title                                           keywords  \\\n",
            "0   1    ML-M2  dataset,R.,Kelley,Pace,Ronald,Barry,Sparse,Spa...   \n",
            "1   2    ML-M5  chapter,BAYESIAN,LEARNING,reasoning,approach,i...   \n",
            "2   3  DS&A-M4  tree,mystery,Jim,Woodring,DataSciencester,VP,T...   \n",
            "3   4    ML-M4  decision,tree,Early,Release,ebook,book,form,au...   \n",
            "4   5  DS&A-M1  joke,data,scientist,statistic,computer,scienti...   \n",
            "\n",
            "     difficulty format    duration   learning_style subject module  \\\n",
            "0  Intermediate    PDF  15 minutes  Reading/Writing      ML     M2   \n",
            "1          Hard    PDF  19 minutes  Reading/Writing      ML     M5   \n",
            "2  Intermediate    PDF  10 minutes  Reading/Writing    DS&A     M4   \n",
            "3  Intermediate    PDF  13 minutes  Reading/Writing      ML     M4   \n",
            "4  Intermediate    PDF  12 minutes  Reading/Writing    DS&A     M1   \n",
            "\n",
            "              file_path  \n",
            "0    /content/ML-M2.pdf  \n",
            "1    /content/ML-M5.pdf  \n",
            "2  /content/DS&A-M4.pdf  \n",
            "3    /content/ML-M4.pdf  \n",
            "4  /content/DS&A-M1.pdf  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Laoding ,preprocessing and building the recommender model"
      ],
      "metadata": {
        "id": "0byh5Wn3DAAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Defining a sample user interactions dataset (later when I make a web page, I can load this content dynamically from user interactions)\n",
        "dataset = [\n",
        "    (1, 1, 'view', '2024-06-23 10:15:00', 4),\n",
        "    (1, 3, 'view', '2024-06-23 10:20:00', 3),\n",
        "    (1, 5, 'view', '2024-06-23 10:25:00', 5),\n",
        "    (1, 7, 'view', '2024-06-23 10:30:00', 2),\n",
        "    (1, 9, 'view', '2024-06-23 10:35:00', 4),\n",
        "    (2, 2, 'view', '2024-06-23 11:00:00', 5),\n",
        "    (2, 4, 'view', '2024-06-23 11:05:00', 1),\n",
        "    (2, 6, 'view', '2024-06-23 11:10:00', 3),\n",
        "    (2, 8, 'view', '2024-06-23 11:15:00', 4),\n",
        "    (2, 10, 'view', '2024-06-23 11:20:00', 2),\n",
        "    (3, 3, 'view', '2024-06-23 11:30:00', 4),\n",
        "    (3, 5, 'view', '2024-06-23 11:35:00', 5),\n",
        "    (3, 7, 'view', '2024-06-23 11:40:00', 3),\n",
        "    (3, 9, 'view', '2024-06-23 11:45:00', 2),\n",
        "    (3, 11, 'view', '2024-06-23 11:50:00', 4),\n",
        "    (4, 4, 'view', '2024-06-23 12:00:00', 5),\n",
        "    (4, 6, 'view', '2024-06-23 12:05:00', 3),\n",
        "    (4, 8, 'view', '2024-06-23 12:10:00', 4),\n",
        "    (4, 10, 'view', '2024-06-23 12:15:00', 2),\n",
        "    (4, 12, 'view', '2024-06-23 12:20:00', 1),\n",
        "    (5, 5, 'view', '2024-06-23 12:30:00', 4),\n",
        "    (5, 7, 'view', '2024-06-23 12:35:00', 3),\n",
        "    (5, 9, 'view', '2024-06-23 12:40:00', 5),\n",
        "    (5, 11, 'view', '2024-06-23 12:45:00', 2),\n",
        "    (5, 13, 'view', '2024-06-23 12:50:00', 4),\n",
        "    (6, 6, 'view', '2024-06-23 13:00:00', 5),\n",
        "    (6, 8, 'view', '2024-06-23 13:05:00', 1),\n",
        "    (6, 10, 'view', '2024-06-23 13:10:00', 3),\n",
        "    (6, 12, 'view', '2024-06-23 13:15:00', 4),\n",
        "    (6, 14, 'view', '2024-06-23 13:20:00', 2),\n",
        "    (7, 7, 'view', '2024-06-23 13:30:00', 3),\n",
        "    (7, 9, 'view', '2024-06-23 13:35:00', 4),\n",
        "    (7, 11, 'view', '2024-06-23 13:40:00', 5),\n",
        "    (7, 13, 'view', '2024-06-23 13:45:00', 2),\n",
        "    (7, 15, 'view', '2024-06-23 13:50:00', 1),\n",
        "    (8, 8, 'view', '2024-06-23 14:00:00', 4),\n",
        "    (8, 10, 'view', '2024-06-23 14:05:00', 5),\n",
        "    (8, 12, 'view', '2024-06-23 14:10:00', 3),\n",
        "    (8, 14, 'view', '2024-06-23 14:15:00', 2),\n",
        "    (8, 16, 'view', '2024-06-23 14:20:00', 4),\n",
        "    (9, 9, 'view', '2024-06-23 14:30:00', 5),\n",
        "    (9, 11, 'view', '2024-06-23 14:35:00', 3),\n",
        "    (9, 13, 'view', '2024-06-23 14:40:00', 4),\n",
        "    (9, 15, 'view', '2024-06-23 14:45:00', 2),\n",
        "    (9, 17, 'view', '2024-06-23 14:50:00', 1),\n",
        "    (10, 10, 'view', '2024-06-23 15:00:00', 3),\n",
        "    (10, 12, 'view', '2024-06-23 15:05:00', 4),\n",
        "    (10, 14, 'view', '2024-06-23 15:10:00', 5),\n",
        "    (10, 16, 'view', '2024-06-23 15:15:00', 2),\n",
        "    (10, 18, 'view', '2024-06-23 15:20:00', 1)\n",
        "]\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(dataset, columns=['user_id', 'pdf_id', 'interaction_type', 'timestamp', 'rating'])\n",
        "\n",
        "# Connect to SQLite database (or create it if not exist)\n",
        "conn = sqlite3.connect('user_interactions.db')\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Create interactions table\n",
        "cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS interactions (\n",
        "        user_id INTEGER,\n",
        "        pdf_id INTEGER,\n",
        "        interaction_type TEXT,\n",
        "        timestamp TEXT,\n",
        "        rating INTEGER,\n",
        "        PRIMARY KEY (user_id, pdf_id, timestamp)\n",
        "    )\n",
        "''')\n",
        "\n",
        "# Insert data into the table\n",
        "for row in dataset:\n",
        "    cursor.execute('''\n",
        "        INSERT OR IGNORE INTO interactions (user_id, pdf_id, interaction_type, timestamp, rating)\n",
        "        VALUES (?, ?, ?, ?, ?)\n",
        "    ''', row)\n",
        "\n",
        "# Commit changes and close connection\n",
        "conn.commit()\n",
        "conn.close()\n",
        "\n",
        "print(\"Dataset successfully stored in SQLite database.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2pLPrD0_Jk0",
        "outputId": "57529236-2501-4b18-9121-978d6b5a2505"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset successfully stored in SQLite database.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the content of the dataset\n",
        "# Connect to SQLite database\n",
        "conn = sqlite3.connect('user_interactions.db')\n",
        "\n",
        "# Query the database to fetch metadata\n",
        "query = \"SELECT * FROM interactions\"\n",
        "df = pd.read_sql_query(query, conn)\n",
        "\n",
        "# Close the database connection\n",
        "conn.close()\n",
        "\n",
        "# Display the loaded dataset\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pK2kUVwTB6Oc",
        "outputId": "00078b21-81c2-441d-a688-ff14ef34084f"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   user_id  pdf_id interaction_type            timestamp  rating\n",
            "0        1       1             view  2024-06-23 10:15:00       4\n",
            "1        1       3             view  2024-06-23 10:20:00       3\n",
            "2        1       5             view  2024-06-23 10:25:00       5\n",
            "3        1       7             view  2024-06-23 10:30:00       2\n",
            "4        1       9             view  2024-06-23 10:35:00       4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess Data\n"
      ],
      "metadata": {
        "id": "Yhwtfn19C57-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convert timestamp to datetime format (if needed)\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "\n",
        "# Drop 'interaction_type' column\n",
        "df.drop('interaction_type', axis=1, inplace=True)\n",
        "\n",
        "# Check for missing values\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Handle missing values if any\n",
        "df = df.dropna()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aFoqXFSCg3z",
        "outputId": "0507d203-7eef-4ccc-c89f-81410d61509b"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user_id      0\n",
            "pdf_id       0\n",
            "timestamp    0\n",
            "rating       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
        "# train_data, test_data\n"
      ],
      "metadata": {
        "id": "vqgl6YHRChM2"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'n_factors': [50, 75, 100, 125, 150, 175, 200],\n",
        "    'n_epochs': [10, 20, 30, 40],\n",
        "    'lr_all': [0.001, 0.002, 0.003, 0.004, 0.005],\n",
        "    'reg_all': [0.01, 0.02, 0.03, 0.04, 0.05, 0.1]\n",
        "}\n",
        "\n",
        "\n",
        "# Define your DataFrame 'df' which includes columns user_id, pdf_id, and rating\n",
        "\n",
        "# Define the Reader and load data\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "data = Dataset.load_from_df(df[['user_id', 'pdf_id', 'rating']], reader)\n",
        "\n",
        "# Instantiate the algorithm\n",
        "algo = SVD()\n",
        "\n",
        "# Grid search\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=5)\n",
        "gs.fit(data)\n",
        "\n",
        "# Best RMSE and MAE scores\n",
        "print(\"Best RMSE score:\", gs.best_score['rmse'])\n",
        "print(\"Best MAE score:\", gs.best_score['mae'])\n",
        "\n",
        "# Best parameters\n",
        "print(\"Best parameters:\", gs.best_params['rmse'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2mrb9EMChcl",
        "outputId": "467fa283-bd2c-4a34-98e4-09b900130636"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RMSE score: 1.3051385514721858\n",
            "Best MAE score: 1.1272607130214753\n",
            "Best parameters: {'n_factors': 100, 'n_epochs': 10, 'lr_all': 0.001, 'reg_all': 0.1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# on chatgpt , for content based filtering try the code"
      ],
      "metadata": {
        "id": "3TG8n04tJLOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CTk8sJjOJLdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gltFOQs5JL0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TDX-TAd7JMB7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}